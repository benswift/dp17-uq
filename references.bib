
@book{tan1992shallow,
  title={Shallow water hydrodynamics: Mathematical theory and numerical solution for a two-dimensional system of shallow-water equations},
  author={Tan, Wei-Yan},
  volume={55},
  year={1992},
  publisher={Elsevier}
}

@article{pdsec15extsgctalg,
  author    = {Strazdins, Peter E and Ali, Md Mohsin and Harding, Brendan},
  title     = {Design and Analysis of Two Highly Scalable Sparse Grid Combination Algorithms},
  journal   = {Journal of Computational Science. Special Issue on Recent Advances in Parallel Techniques for Scientific Computing},
  volume    = {17},
  number    = {3},
  year      = {2016},
  pages     = {547--561},
  month     = {Nov},

}

@INPROCEEDINGS{sgctalg15,
    author = {Strazdins, Peter E and Ali, Md Mohsin and Harding, Brendan},
    title = {Highly Scalable Algorithms for the Sparse Grid Combination Technique},
    booktitle = {Proceedings of the IEEE 29th International Parallel \& Distributed Processing Symposium Workshops (IPDPSW 2015)},
    address = {Hyderabad, India},
    pages = {941--950},
    doi = {10.1109/IPDPSW.2015.76},
    days = {25--29},
    month = {May},
    year = {2015},
}


@INPROCEEDINGS{parSGCT16,
    author = {Strazdins, Peter E and Ali, Md Mohsin and Debusschere, Bert},
    title = {{Application Fault Tolerance for Shrinking Resources via the
Sparse Grid Combination Technique}},
    booktitle = {Proceedings of the IEEE 30th International Parallel \& Distributed Processing Symposium Workshops (IPDPSW 2016)},
    address = {Chicago, USA},
    pages = {1232--36},
    month = {May},
    year = {2016},
}


@manual{anugamanual,
title={ANUGA User Manual},
author={Roberts, S and Nielsen, O. and Gray, D. and Sexton, J. and Davies, G.},
organization={Geoscience Australia},
year={2015}
}

@article{nielsen2005hydrodynamic,
title={Hydrodynamic modelling of coastal inundation},
author={Nielsen, O and Roberts, S and Gray, D and McPherson, A and Hitchman, A},
journal={MODSIM 2005 International Congress on Modelling and Simulation},
pages={518--523},
year={2005}
}



@inproceedings{martin2016intelligent,
  title={Intelligent Agents and Networked Buttons Improve Free-Improvised Ensemble Music-Making on Touch Screens},
  author={Martin, Charles and Gardner, Henry and Swift, Ben and  Martin, Michael},
  booktitle={Proceedings of the 34nd annual ACM conference on Human factors in computing systems},
  pages={to appear, May, 2016},
  year={2016},
  organization={ACM}
}

@inproceedings{martin2015tracking,
  title={Tracking Ensemble Performance on Touch-Screens with Gesture Classification and Transition Matrices},
  author={Martin, Charles and Gardner, Henry and Swift, Ben},
  booktitle={Proc. NIME},
  volume={15},
  year={2015}
}

@inproceedings{swift2014coding,
  title={Coding livecoding},
  author={Swift, Ben and Sorensen, Andrew and Martin, Michael and Gardner, Henry},
  booktitle={Proceedings of the 32nd annual ACM conference on Human factors in computing systems},
  pages={1021--1024},
  year={2014},
  organization={ACM}
}

@inproceedings{swift2013visual,
  title={Visual code annotations for cyberphysical programming},
  author={Swift, Ben and Sorensen, Andrew and Gardner, Henry and Hosking, John},
  booktitle={Proceedings of the 1st International Workshop on Live Programming},
  pages={27--30},
  year={2013},
  organization={IEEE Press}
}

@article{maceachrenvisual2015,
  title = {Visual {{Analytics}} and {{Uncertainty}}: {{Its Not About}} the {{Data}}},
  timestamp = {2016-01-19T22:40:27Z},
  author = {MacEachren, Alan M.},
  date = {2015},
  file = {MacEachrenEUROVAfinal20150402.pdf:/Users/ben/Documents/zotero/storage/IVCND3FM/MacEachrenEUROVAfinal20150402.pdf:application/pdf}
}


@article{ramchurn2016human,
  title={Human--agent collaboration for disaster response},
  author={Ramchurn, Sarvapali D and Wu, Feng and Jiang, Wenchao and Fischer, Joel E and Reece, Steve and Roberts, Stephen and Rodden, Tom and Greenhalgh, Chris and Jennings, Nicholas R},
  journal={Autonomous Agents and Multi-Agent Systems},
  volume={30},
  number={1},
  pages={82--111},
  year={2016},
  publisher={Springer}
}



@article{gonzalezdecision2005,
  title = {Decision support for real-time, dynamic decision-making tasks},
  volume = {96},
  issn = {0749-5978},
  url = {http://www.sciencedirect.com/science/article/pii/S0749597804000949},
  doi = {10.1016/j.obhdp.2004.11.002},
  abstract = {By definition, dynamic decision making dictates that multiple and interrelated decisions be made in a continuously changing environment. Such decision making is difficult and often taxes individuals’ cognitive resources. Here I investigated ways in which to support decision making in these environments. I evaluated three forms of decision support: outcome feedback, cognitive feedback, and feedforward that incorporated (to varying degrees) common features of learning theories associated with dynamic tasks. Participants in a laboratory experiment performed a real-time, dynamic decision-making task while receiving one of the different types of decision support. During the first 2 days, individuals received one type of decision support, but on the third day they performed the task without this support. Participants who received feedforward improved their performance considerably and continued to exhibit improved performance even after discontinuation of the decision support on the third day. Neither outcome feedback nor cognitive feedback resulted in improved performance. More research is necessary to conclusively identify the best forms of dynamic decision-making support and their durability when transferred to new tasks.},
  timestamp = {2015-01-21T05:11:06Z},
  number = {2},
  journaltitle = {Organizational Behavior and Human Decision Processes},
  journal = {Organizational Behavior and Human Decision Processes},
  year={2015},
  shortjournal = {Organizational Behavior and Human Decision Processes},
  author = {Gonzalez, Cleotilde},
  urldate = {2015-01-21},
  date = {2005-03},
  pages = {142--154},
  keywords = {Cognitive feedback,Cognitive support,Dynamic decision making,Feedback,Feedforward},
  file = {ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/C2WAPRGF/S0749597804000949.html:;Gonzalez2005Decision support for real-time, dynamic decision-making tasks.pdf:/Users/ben/Documents/zotero/storage/U4H78N7Z/Gonzalez2005Decision support for real-time, dynamic decision-making tasks.pdf:application/pdf}
  }


@article{wallaceDecision1985,
  title = {Decision {{Support Systems}} for {{Disaster Management}}},
  volume = {45},
  issn = {0033-3352},
  doi = {10.2307/3135008},
  abstract = {This paper is designed to provide a conceptual framework for the employment of decision support systems (DSS) in the field of disaster management. This framework will incorporate the following dimensions: (1) definition of DSS and its differences from MIS in the public sector; (2) stages in the life cycle of a disaster and the types of events occurring within stages; (3) a framework for conceptualizing decision making in disaster management at various levels-operational, tactical, and strategic; (4) a matrix of information and modeling needs of planners and decision makers within each stage; and (5) selected examples of DSS applications and prototypes which have been developed on microcomputers which will serve to illustrate the role of DSS in the disaster management.},
  timestamp = {2016-01-20T23:48:57Z},
  eprinttype = {jstor},
  eprint = {3135008},
  journaltitle = {Public Administration Review},
  journal = {Public Administration Review},
  year = {185},
  shortjournal = {Public Administration Review},
  author = {Wallace, William A. and De Balogh, Frank},
  date = {1985},
  pages = {134--146},
  file = {JSTOR Full Text PDF:/Users/ben/Documents/zotero/storage/PF5KRT7H/Wallace and De Balogh - 1985 - Decision Support Systems for Disaster Management.pdf:application/pdf}
}



@article{spragueframework1980,
  title = {A {{Framework}} for the {{Development}} of {{Decision Support Systems}}},
  volume = {4},
  issn = {0276-7783},
  doi = {10.2307/248957},
  abstract = {This article proposes a framework to explore the nature, scope, and content of the evolving topic of Decision Support Systems (DSS). The first part of the framework considers (a) three levels of technology which have been designated DSS, (b) the developmental approach that is evolving for the creation of a DSS, and (c) the roles of several key types of people in the building and use of a DSS. The second part develops a descriptive model to assess the performance objectives and the capabilities of a DSS as viewed by three of the major participants in their continued development and use. The final section outlines several issues in the future growth and development of a DSS as a potentially valuable type of information system in organizations.},
  timestamp = {2016-01-20T23:45:16Z},
  eprinttype = {jstor},
  eprint = {248957},
  number = {4},
  journaltitle = {MIS Quarterly},
  journal = {MIS Quarterly},
  year={1980},
  shortjournal = {MIS Quarterly},
  author = {Sprague, Ralph H.},
  date = {1980},
  pages = {1--26},
  file = {JSTOR Full Text PDF:/Users/ben/Documents/zotero/storage/IZ9QWQH7/Sprague - 1980 - A Framework for the Development of Decision Suppor.pdf:application/pdf}
}



@article{zackrole2007,
  title = {The role of decision support systems in an indeterminate world},
  volume = {43},
  issn = {0167-9236},
  url = {http://www.sciencedirect.com/science/article/pii/S0167923606001308},
  doi = {10.1016/j.dss.2006.09.003},
  abstract = {Decision making involves processing or applying information and knowledge, and the appropriate information/knowledge mix depends on the characteristics of the decision making context. Information (or its absence) is central to decision making situations involving uncertainty and complexity, while knowledge (or its absence) is associated with problems of ambiguity and equivocality. This paper proposes that computer-based decision support technologies are appropriate to supporting decision making under conditions of uncertainty and complexity, while human-centric approaches may be more appropriate under conditions of ambiguity or equivocality. Both approaches, however, must be tightly integrated for organizational learning to occur. The framework is illustrated with a case study of the implementation of a decision support system used for price quoting in a leasing company.},
  timestamp = {2016-01-19T22:21:02Z},
  number = {4},
  journaltitle = {Decision Support Systems},
  journal = {Decision Support Systems},
  year={2007},
  shortjournal = {Decision Support Systems},
  series = {Special Issue Clusters},
  author = {Zack, Michael H.},
  urldate = {2016-01-19},
  date = {2007-08},
  pages = {1664--1674},
  keywords = {Ambiguity,Complexity,Decision Support Systems,Equivocality,knowledge management,Task technology fit,Uncertainty},
  file = {ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/8BGQTH74/Zack - 2007 - The role of decision support systems in an indeter.pdf:application/pdf;ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/XJDAT8S7/S0167923606001308.html:}
}



@article{vandenhonert2011,
  title = {The 2011 {{Brisbane Floods}}: {{Causes}}, {{Impacts}} and {{Implications}}},
  volume = {3},
  rights = {http://creativecommons.org/licenses/by/3.0/},
  url = {http://www.mdpi.com/2073-4441/3/4/1149},
  doi = {10.3390/w3041149},
  shorttitle = {The 2011 {{Brisbane Floods}}},
  abstract = {On 13th January 2011 major flooding occurred throughout most of the Brisbane River catchment, most severely in Toowoomba and the Lockyer Creek catchment (where 23 people drowned), the Bremer River catchment and in Brisbane, the state capital of Queensland. Some 56,200 claims have been received by insurers with payouts totalling {\textdollar}2.55 billion. This paper backgrounds weather and climatic factors implicated in the flooding and the historical flood experience of Brisbane. We examine the time history of water releases from the Wivenhoe dam, which have been accused of aggravating damage downstream. The dam was built in response to even worse flooding in 1974 and now serves as Brisbane’s main water supply. In our analysis, the dam operators made sub-optimal decisions by neglecting forecasts of further rainfall and assuming a ‘no rainfall’ scenario. Questions have also been raised about the availability of insurance cover for riverine flood, and the Queensland government’s decision not to insure its infrastructure. These and other questions have led to Federal and State government inquiries. We argue that insurance is a form of risk transfer for the residual risk following risk management efforts and cannot in itself be a solution for poor land-use planning. With this in mind, we discuss the need for risk-related insurance premiums to encourage flood risk mitigating behaviours by all actors, and for transparency in the availability of flood maps. Examples of good flood risk management to arise from this flood are described.},
  timestamp = {2016-01-22T00:12:53Z},
  langid = {english},
  number = {4},
  journaltitle = {Water},
  journal = {Water},
  year = {2011},
  shortjournal = {Water},
  author = {van den Honert, Robin C. and McAneney, John},
  urldate = {2016-01-22},
  date = {2011-12-09},
  pages = {1149--1173},
  keywords = {Brisbane River,flood,flood risk management,insurance,January 2011,land use planning,water release strategy},
  options = {useprefix=true},
  file = {Full Text PDF:/Users/ben/Documents/zotero/storage/6HXIMEK4/van den Honert and McAneney - 2011 - The 2011 Brisbane Floods Causes, Impacts and Impl.pdf:application/pdf;Snapshot:/Users/ben/Documents/zotero/storage/ZCIK54AI/1149.html:}
}

@article{BungartzGriebel2004,
author = {Bungartz,Hans-Joachim and Griebel,Michael},
title = {Sparse grids},
journal = {Acta Numerica},
volume = {13},
month = {5},
year = {2004},
issn = {1474-0508},
pages = {147--269},
numpages = {123},
doi = {10.1017/S0962492904000182},
URL = {http://journals.cambridge.org/articleS0962492904000182},
}

@inbook {Zabaras2010,
author = {Zabaras, N.},
title = {Solving Stochastic Inverse Problems: A Sparse Grid Collocation Approach},
publisher = {John Wiley \& Sons, Ltd},
isbn = {9780470685853},
url = {http://dx.doi.org/10.1002/9780470685853.ch14},
doi = {10.1002/9780470685853.ch14},
pages = {291--319},
keywords = {solving stochastic inverse problems - sparse grid collocation approach, quantifying and modeling, effect of input uncertainties - and response of PDEs using non-statistical methods, generalized polynomial chaos expansion (GPCE) methods, Smolyak algorithm, building sparse grid interpolants - in high-dimensional space, stochastic design problems, two proof-of-concept design applications - with topological, material and operating uncertainties, mathematical and algorithmic aspects - posing and solving stochastic inverse problems, hierarchical-basis based adaptive sparse collocation, data structure for dimensional scalability, stochastic regularization of unknown stochastic fields},
booktitle = {Large-Scale Inverse Problems and Quantification of Uncertainty},
year = {2010},
}

@article{deBaarHarding2015,
	author  = {de Baar, Jouke H. S. and Brendan  Harding},
	title   = {A Gradient-Enhanced Sparse Grid Algorithm for Uncertainty Quantification},
	journal = {International Journal for Uncertainty Quantification},
	issn    = {2152-5080},
	year    = {2015},
	volume  = {5},
	number  = {5},
	pages   = {453--468}
}

@inproceedings{Griebel1990,
  author = { M.~Griebel and M.~Schneider and C.~Zenger},
  title = {A combination technique for the solution of sparse grid
		  problems},
  editor = {P. de Groen and R. Beauwens},
  booktitle = { {Iterative Methods in Linear Algebra}},
  pages = {263--281},
  publisher = {IMACS, Elsevier, North Holland},
  year = {1992},
  note = {also as SFB Bericht, 342/19/90 A, Institut f\"{u}r
		  Informatik, TU M\"{u}nchen, 1990},
  annote = {series},
  ps = {http://wissrech.ins.uni-bonn.de/research/pub/griebel/griesiam.ps.gz 1}
}

@inproceedings{AliEtal2015,
    author = {Ali, Md Mohsin and Strazdins, Peter E and Harding, Brendan and Hegland, Markus and Larson, Jay W},
    title = {A Fault-Tolerant Gyrokinetic Plasma Application using the Sparse Grid Combination Technique},
    booktitle = {Proceedings of the 2015 International Conference on High Performance Computing \& Simulation ({HPCS} 2015)},
    address = {Amsterdam, The Netherlands},
    pages = {499--507},
    days = {20--24},
    month = {July},
    year = {2015},
    note = {Outstanding paper award},
} 


@article{HardingHLS2015,
author = {Brendan Harding and Markus Hegland and Jay Larson and James Southern},
title = {Fault Tolerant Computation with the Sparse Grid Combination Technique},
journal = {SIAM Journal on Scientific Computing},
volume = {37},
number = {3},
pages = {C331-C353},
year = {2015},
doi = {10.1137/140964448},
URL = {http://dx.doi.org/10.1137/140964448},
eprint = {http://dx.doi.org/10.1137/140964448}
}


@article{deBaarRDM2015,
  title = {Uncertainty quantification for a sailing yacht hull, using multi-fidelity kriging},
  volume = {123},
  issn = {0045-7930},
  url = {http://www.sciencedirect.com/science/article/pii/S0045793015003382},
  doi = {10.1016/j.compfluid.2015.10.004},
  abstract = {Uncertainty quantification (UQ) for CFD-based ship design can require a large number of simulations, resulting in significant overall computational cost. Presently, we use an existing method, multi-fidelity Kriging, to reduce the number of simulations required for the UQ analysis of the performance of a sailing yacht hull, considering uncertainties in the tank blockage, mass and centre of gravity. We compare the UQ results with experimental values.},
  timestamp = {2015-10-31T03:28:55Z},
  journaltitle = {Computers \& Fluids},
  journal = {Computers \& Fluids},
  year={2015},
  shortjournal = {Computers \& Fluids},
  author = {de Baar, Jouke and Roberts, Stephen and Dwight, Richard and Mallol, Benoit},
  urldate = {2015-10-31},
  date = {2015-12-21},
  pages = {185--201},
  keywords = {Free-surface,Kriging,Multi-fidelity,RANS,Uncertainty quantification},
  options = {useprefix=true},
  file = {ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/MU264UBN/S0045793015003382.html:;1-s2.0-S0045793015003382-main.pdf:/Users/ben/Documents/zotero/storage/XRGHIXWV/1-s2.0-S0045793015003382-main.pdf:application/pdf}
}

@incollection{JakemanRoberts2013,
year={2013},
isbn={978-3-642-31702-6},
booktitle={Sparse Grids and Applications},
volume={88},
series={Lecture Notes in Computational Science and Engineering},
editor={Garcke, Jochen and Griebel, Michael},
doi={10.1007/978-3-642-31703-3_9},
title={Local and Dimension Adaptive Stochastic Collocation for Uncertainty Quantification},
url={http://dx.doi.org/10.1007/978-3-642-31703-3_9},
publisher={Springer Berlin Heidelberg},
author={Jakeman, JohnD. and Roberts, StephenG.},
pages={181-203},
language={English}
}

@article{LiebermanEtal2010,
author = {Chad Lieberman and Karen Willcox and Omar Ghattas},
title = {Parameter and State Model Reduction for Large-Scale Statistical Inverse Problems},
journal = {SIAM Journal on Scientific Computing},
volume = {32},
number = {5},
pages = {2523-2542},
year = {2010},
doi = {10.1137/090775622},
URL = { http://dx.doi.org/10.1137/090775622},
eprint = {   http://dx.doi.org/10.1137/090775622}
}

@article{ChenSchwab2015,
title = "Sparse-grid, reduced-basis Bayesian inversion ",
journal = "Computer Methods in Applied Mechanics and Engineering ",
volume = "297",
number = "",
pages = "84 - 115",
year = "2015",
note = "",
issn = "0045-7825",
doi = "http://dx.doi.org/10.1016/j.cma.2015.08.006",
url = "http://www.sciencedirect.com/science/article/pii/S0045782515002601",
author = "Peng Chen and Christoph Schwab",
}


@article{drewsinformation2015,
  title = {Information {{Search}} and {{Decision Making}} in {{Computer-Based Wildfire Simulations}}},
  issn = {1555-3434,},
  url = {http://edm.sagepub.com.virtual.anu.edu.au/content/early/2015/05/26/1555343415586478},
  doi = {10.1177/1555343415586478},
  abstract = {Decision making in complex environments has been investigated in many domains, including medicine, aviation, business, and police operations. However, how incident commanders (ICs) make protective-action recommendations (PARs) to populations exposed to wildfire risks is underinvestigated. In this study we examined the effect of expertise on IC non-time-limited information search and decision making and how ICs update information during the evolution of complex, computer-simulated wildfire scenarios. The results indicate that higher expertise reduces the overall amount of information being searched for, without affecting the quality of PAR decisions. In addition, a statistical trend suggests that information updating during the progression of the scenario involves disproportionate less-static information versus dynamic information. Finally, ICs demonstrated a strong preference for evacuation recommendations over alternative recommendations, even when an evacuation may result in less optimal outcomes.},
  timestamp = {2016-01-26T02:23:40Z},
  langid = {english},
  journaltitle = {Journal of Cognitive Engineering and Decision Making},
  journal = {Journal of Cognitive Engineering and Decision Making},
  year={2015},
  shortjournal = {Journal of Cognitive Engineering and Decision Making},
  author = {Drews, Frank A. and Siebeneck, Laura and Cova, Thomas},
  urldate = {2016-01-26},
  date = {2015-05-29},
  pages = {1555343415586478},
  keywords = {Decision making,information board,information search,simulation,Wildfire},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/65KZJI4H/1555343415586478.html:;Full Text PDF:/Users/ben/Documents/zotero/storage/JIB65WV8/Drews et al. - 2015 - Information Search and Decision Making in Computer.pdf:application/pdf}
}

@article{nealeNavigating2015,
  title = {Navigating scientific uncertainty in wildfire and flood risk mitigation: {{A}} qualitative review},
  volume = {13},
  issn = {2212-4209},
  url = {http://www.sciencedirect.com/science/article/pii/S221242091530025X},
  doi = {10.1016/j.ijdrr.2015.06.010},
  shorttitle = {Navigating scientific uncertainty in wildfire and flood risk mitigation},
  abstract = {Natural hazards are complex events whose mitigation has generated a diverse field of specialised natural science expertise that is drawn upon by a wide range of practitioners and decision-makers. In this paper, the authors bring natural science research, risk studies and science and technology studies together in aid of clarifying the role scientific uncertainties play in the mitigation of natural hazards and their associated risks. Given that uncertainty is a necessary part of scientific practise and method, those engaged in risk mitigation must manage these scientific uncertainties in their decision-making just as, equally, social science researchers, stakeholders and others hoping to understand risk mitigation must understand their character and influence. To this end, the authors present the results of an extensive literature review of scientific uncertainties as they emerge in relation to wildfire and flood risk mitigation in Australia. The results are both a survey of these major uncertainties and a novel categorisation within which a variety of expert and non-expert audiences might discuss and translate the scientific uncertainties that are encountered and managed in risk mitigation.},
  timestamp = {2016-01-26T02:23:04Z},
  journaltitle = {International Journal of Disaster Risk Reduction},
  journal = {International Journal of Disaster Risk Reduction},
  year={2015},
  shortjournal = {International Journal of Disaster Risk Reduction},
  author = {Neale, Timothy and Weir, Jessica K.},
  urldate = {2016-01-26},
  date = {2015-09},
  pages = {255--265},
  keywords = {Australia,flood,Risk mitigation,Social science,Wildfire},
  file = {ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/9HKP3UR7/S221242091530025X.html:;ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/G369R2M7/Neale and Weir - 2015 - Navigating scientific uncertainty in wildfire and .pdf:application/pdf}
}

@article{alexanderLimitations2013,
  title = {Limitations on the accuracy of model predictions of wildland fire behaviour: {{A}} state-of-the-knowledge overview},
  volume = {89},
  issn = {0015-7546},
  url = {http://pubs.cif-ifc.org.virtual.anu.edu.au/doi/abs/10.5558/tfc2013-067},
  doi = {10.5558/tfc2013-067},
  shorttitle = {Limitations on the accuracy of model predictions of wildland fire behaviour},
  abstract = {The degree of accuracy in model predictions of wildland fire behaviour characteristics are dependent on the model's applicability to a given situation, the validity of the model's relationships, and the reliability of the model input data. While much progress has been made by fire behaviour research in the past 35 years or so in addressing these three sources of model error, the accuracy in model predictions are still very much at the mercy of our present understanding of the natural phenomena exhibited by free-burning wildland fires and the inherent temporal and spatial variability in the fire environment. This paper will serve as a state-of-the-art primer on the subject of error sources in model predictions of wildland fire behaviour and includes a short historical overview of wildland fire behaviour research as it relates to model development.},
  timestamp = {2016-01-26T02:21:58Z},
  number = {03},
  journaltitle = {The Forestry Chronicle},
  journal = {The Forestry Chronicle},
  year={2016},
  shortjournal = {The Forestry Chronicle},
  author = {Alexander, Martin E. and Cruz, Miguel G.},
  urldate = {2016-01-26},
  date = {2013-01-01},
  pages = {372--383},
  keywords = {fire behaviour prediction,fire environment,fire modelling,model applicability,model input accuracy,model relationships,rate of fire spread},
  file = {Full Text PDF:/Users/ben/Documents/zotero/storage/7V6PGCZ6/Alexander and Cruz - 2013 - Limitations on the accuracy of model predictions o.pdf:application/pdf;Snapshot:/Users/ben/Documents/zotero/storage/ZVCX2NXS/tfc2013-067.html:}
}

@article{oneillresponding2012,
  title = {Responding to bushfire risk: the need for transformative adaptation},
  volume = {7},
  issn = {1748-9326},
  url = {http://stacks.iop.org/1748-9326/7/i=1/a=014018},
  doi = {10.1088/1748-9326/7/1/014018},
  shorttitle = {Responding to bushfire risk},
  abstract = {The 2009 ‘Black Saturday’ bushfires led to 172 civilian deaths, and were proclaimed as one of Australia’s worst natural disasters. The Victorian Bushfires Royal Commission was set up in the wake of the fires to investigate the circumstances surrounding the death of each fatality. Here, results from an analysis undertaken for the Commission to examine the household preparedness policy ‘Prepare, Stay and Defend, or Leave Early’ (‘Stay or Go’), plus an examination of the Commission’s recommendations, are explored in the broader context of adaptation to bushfire. We find Victoria ill adapted to complex bushfire risk events like Black Saturday due to changing settlement patterns and the known vulnerabilities of populations living in fire prone areas, and increasingly in the future due to the influence of climate change extending fire seasons and their severity. We suggest that uncertainty needs to be better acknowledged and managed in fire risk situations, and that the responsibility for fire preparedness should be more justly distributed. We suggest that a transformation in adaptation is required to effectively manage complex bushfire risk events like Black Saturday, and provide four key ways in which transformation in bushfire preparedness could be achieved.},
  timestamp = {2016-01-26T02:20:49Z},
  langid = {english},
  number = {1},
  journaltitle = {Environmental Research Letters},
  journal = {Environmental Research Letters},
  year={2012},
  shortjournal = {Environ. Res. Lett.},
  author = {O’Neill, Saffron J. and Handmer, John},
  urldate = {2016-01-26},
  date = {2012},
  pages = {014018},
  file = {IOP Full Text PDF:/Users/ben/Documents/zotero/storage/A5AIRUVG/O’Neill and Handmer - 2012 - Responding to bushfire risk the need for transfor.pdf:application/pdf}
}

@article{mclennanreframing2012,
  title = {Reframing responsibility-sharing for bushfire risk management in {{Australia}} after {{Black Saturday}}},
  volume = {11},
  issn = {1747-7891},
  url = {http://dx.doi.org/10.1080/17477891.2011.608835},
  doi = {10.1080/17477891.2011.608835},
  abstract = {In the context of risk, the concept of responsibility incorporates the notion that certain parties have a prospective obligation to undertake actions to manage risk. However, differences in judgements about which parties are responsible for which aspects of risk management often lead to social conflict. This paper uses the heuristic of a ‘responsibility continuum for risk management’ to highlight how judgements of the obligations of different parties to manage risk are underpinned by particular ways of framing responsibility-sharing. It then uses the heuristic to examine the case of a Royal Commission enquiry into Australia's deadliest bushfire (wildfire) event, known as Black Saturday. It argues that the Royal Commission reframed responsibility-sharing away from an emphasis on the self-reliance of at-risk communities towards a greater degree of responsibility for government emergency management agencies. This is particularly the case when fire conditions are extreme and where vulnerable people are at risk. This position runs counter to an international trend in policy towards placing greater responsibility for risk management on at-risk communities. However, the Commission's analysis is strong for the distribution of responsibility across government and between government and communities, but is weaker across the government--private sector interface and where the factors underlying vulnerability are concerned.},
  timestamp = {2016-01-26T02:20:00Z},
  number = {1},
  journaltitle = {Environmental Hazards},
  shortjournal = {Environ. Hazards},
  author = {McLennan, Blythe J. and Handmer, John},
  urldate = {2016-01-26},
  date = {2012-03-01},
  pages = {1--15},
  file = {Full Text PDF:/Users/ben/Documents/zotero/storage/DIN7JM2H/McLennan and Handmer - 2012 - Reframing responsibility-sharing for bushfire risk.pdf:application/pdf;Snapshot:/Users/ben/Documents/zotero/storage/PRT29Z6B/17477891.2011.html:}
}

@article{cruzAnatomy2012,
  title = {Anatomy of a catastrophic wildfire: {{The Black Saturday Kilmore East}} fire in {{Victoria}}, {{Australia}}},
  volume = {284},
  issn = {0378-1127},
  url = {http://www.sciencedirect.com/science/article/pii/S0378112712001223},
  doi = {10.1016/j.foreco.2012.02.035},
  shorttitle = {Anatomy of a catastrophic wildfire},
  abstract = {The 7 February 2009 wildfires in south-eastern Australia burned over 450,000 ha and resulted in 173 human fatalities. The Kilmore East fire was the most significant of these fires, burning 100,000 ha in less than 12 h and accounting for 70\% of the fatalities. We report on the weather conditions, fuels and propagation of this fire to gain insights into the physical processes involved in high intensity fire behaviour in eucalypt forests. Driven by a combination of exceedingly dry fuel and near-gale to gale force winds, the fire developed a dynamic of profuse short range spotting that resulted in rates of fire spread varying between 68 and 153 m\/min and average fireline intensities up to 88,000 kW\/m. Strong winds aloft and the development of a strong convection plume led to the transport of firebrands over considerable distances causing the ignition of spotfires up to 33 km ahead of the main fire front. The passage of a wind change between 17:30 and 18:30 turned the approximately 55 km long eastern flank of the fire into a headfire. Spotting and mass fire behaviour associated with this wide front resulted in the development of a pyrocumulonimbus cloud that injected smoke and other combustion products into the lower stratosphere. The benchmark data collected in this case study will be invaluable for the evaluation of fire behaviour models. The study is also a source of real world data from which simulation studies investigating the impact of landscape fuel management on the propagation of fire under the most severe burning conditions can be undertaken.},
  timestamp = {2016-01-26T02:19:17Z},
  journaltitle = {Forest Ecology and Management},
  shortjournal = {Forest Ecology and Management},
  author = {Cruz, M. G. and Sullivan, A. L. and Gould, J. S. and Sims, N. C. and Bannister, A. J. and Hollis, J. J. and Hurley, R. J.},
  urldate = {2016-01-26},
  date = {2012-11-15},
  pages = {269--285},
  keywords = {Crown fire,eucalyptus,Megafire,Pyrocumulonimbus,Spotting,Wildland-urban interface},
  file = {ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/7CR7NS7Z/S0378112712001223.html:;ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/Z5D86N72/Cruz et al. - 2012 - Anatomy of a catastrophic wildfire The Black Satu.pdf:application/pdf}
}

@article{rothGeovisual2016,
  title = {Geovisual analytics and the science of interaction: an empirical interaction study},
  volume = {43},
  issn = {1523-0406},
  url = {http://dx.doi.org/10.1080/15230406.2015.1021714},
  doi = {10.1080/15230406.2015.1021714},
  shorttitle = {Geovisual analytics and the science of interaction},
  abstract = {Among the most pressing research and development challenges facing geovisual analytics is the establishment of a science of interaction to inform the design of visual interfaces to computational methods. The most promising work on interaction to date has attempted to identify and articulate the fundamental interaction primitives that define the complete design space for the user experience. In this paper, we take the logical next step beyond this prior research, reporting on a controlled interaction study to learn how variation in interaction primitive combinations impacts broader interaction strategies (i.e., to learn how interaction primitives relate for both design and use). GeoVISTA CrimeViz -- a geovisual analytics application developed in partnership with the Harrisburg (Pennsylvania, USA) Bureau of Police -- was leveraged as a living laboratory for examining the nature of interaction strategies as they are built from interaction primitives. Ten law enforcement officers with the Harrisburg Bureau of Police completed a set of 15 benchmark tasks based on a three-stage interaction primitive taxonomy while their interactions were logged. Experimental results revealed several noteworthy characteristics of the relationship between interaction primitives and interaction strategies, including an increased reliance on the interface as the objective increases in sophistication and the effectiveness of, although at times over-reliance upon, Shneiderman’s visual information-seeking mantra as an analytical strategy. Further, consistently successful and suboptimal interaction strategies were characterized in terms of their constituent interaction primitives and articulated as user personas, allowing for the establishment of interface design and use recommendations for circumventing negative personas.},
  timestamp = {2016-01-26T01:32:39Z},
  number = {1},
  journaltitle = {Cartography and Geographic Information Science},
  shortjournal = {Cartogr. Geogr. Inf. Sci.},
  author = {Roth, Robert E. and MacEachren, Alan M.},
  urldate = {2016-01-26},
  date = {2016-01-01},
  pages = {30--54},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/5JB7CIXU/15230406.2015.html:;Full Text PDF:/Users/ben/Documents/zotero/storage/XV2SEH29/Roth and MacEachren - 2016 - Geovisual analytics and the science of interaction.pdf:application/pdf}
}

@article{williamsShaping2015,
  title = {Shaping {{Problems}}, {{Not Decisions}}:{{When Decision Makers Leverage Visual Analytics}}},
  url = {http://aisel.aisnet.org/amcis2015/BizAnalytics/GeneralPresentations/15},
  shorttitle = {Shaping {{Problems}}, {{Not Decisions}}},
  timestamp = {2016-01-26T01:32:14Z},
  journaltitle = {AMCIS 2015 Proceedings},
  shortjournal = {AMCIS 2015 Proc.},
  author = {Williams, Brian and Boland, Richard and Lyytinen, Kalle},
  date = {2015-06-26},
  file = {AIS Electronic Library (AISeL) - AMCIS 2015 Proceedings\: Shaping Problems, Not Decisions\:When Decision Makers Leverage Visual Analytics:/Users/ben/Documents/zotero/storage/9X3KTQ96/15.html:}
}

@incollection{sedigHumancentered2014,
  title = {Human-{{Centered Interactivity}} of {{Visualization Tools}}: {{Micro}}- and {{Macro}}-level {{Considerations}}},
  rights = {©2014 Springer Science+Business Media New York},
  isbn = {978-1-4614-7484-5 978-1-4614-7485-2},
  url = {http://link.springer.com.virtual.anu.edu.au/chapter/10.1007/978-1-4614-7485-2_29},
  shorttitle = {Human-{{Centered Interactivity}} of {{Visualization Tools}}},
  abstract = {Visualization tools can support and enhance the performance of complex cognitive activities such as sense making, problem solving, and analytical reasoning. To do so effectively, however, a human-centered approach to their design and evaluation is required. One way to make visualization tools human-centered is to make them interactive. Although interaction allows a user to adjust the features of the tool to suit his or her cognitive and contextual needs, it is the quality of interaction that largely determines how well complex cognitive activities are supported. In this chapter, interactivity is conceptualized as the quality of interaction. As interactivity is a broad and complex construct, we categorize it into two levels: micro and macro. Interactivity at the micro level emerges from the structural elements of individual interactions. Interactivity at the macro level emerges from the combination, sequencing, and aggregate properties and relationships of interactions as a user performs an activity. Twelve micro-level interactivity elements and five macro-level interactivity factors are identified and characterized. The framework presented in this chapter can provide some structure and facilitate a systematic approach to design and evaluation of interactivity in human-centered visualization tools.},
  timestamp = {2016-01-26T01:31:12Z},
  langid = {english},
  booktitle = {Handbook of {{Human Centric Visualization}}},
  publisher = {{Springer New York}},
  author = {Sedig, Kamran and Parsons, Paul and Dittmer, Mark and Haworth, Robert},
  editor = {Huang, Weidong},
  urldate = {2016-01-26},
  date = {2014},
  pages = {717--743},
  keywords = {Artificial Intelligence (incl. Robotics),Computer Graphics,Models and Principles,User Interfaces and Human Computer Interaction,Visualization},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/67MMIPKS/978-1-4614-7485-2_29.html:;HCV-IVT2013.pdf:/Users/ben/Documents/zotero/storage/WK7HPNNF/HCV-IVT2013.pdf:application/pdf},
  doi = {10.1007/978-1-4614-7485-2_29}
}

@article{pohlAnalysing2012,
  title = {Analysing {{Interactivity}} in {{Information Visualisation}}},
  volume = {26},
  issn = {0933-1875, 1610-1987},
  url = {http://link.springer.com.virtual.anu.edu.au/article/10.1007/s13218-012-0167-6},
  doi = {10.1007/s13218-012-0167-6},
  abstract = {Modern information visualisation systems do not only support interactivity but also increasingly complex problem solving. In this study we compare two interactive information visualisation systems: VisuExplore and Gravi++. By analysing logfiles we were able to identify sets of activities and interaction patterns users followed while working with these systems. These patterns are an indication of strategies users adopt to find solutions. Identifying such patterns may help in improving the design of future information visualisation systems.},
  timestamp = {2016-01-26T01:30:59Z},
  langid = {english},
  number = {2},
  journaltitle = {KI - Künstliche Intelligenz},
  shortjournal = {Künstl Intell},
  author = {Pohl, Margit and Wiltner, Sylvia and Miksch, Silvia and Aigner, Wolfgang and Rind, Alexander},
  urldate = {2016-01-26},
  date = {2012-01-25},
  pages = {151--159},
  keywords = {Artificial Intelligence (incl. Robotics),Evaluation,Information visualisation,Problem solving,Software Engineering/Programming and Operating Systems,Software logging},
  file = {Full Text PDF:/Users/ben/Documents/zotero/storage/PWXPXPBW/Pohl et al. - 2012 - Analysing Interactivity in Information Visualisati.pdf:application/pdf;Snapshot:/Users/ben/Documents/zotero/storage/SAGZPRS3/s13218-012-0167-6.html:}
}

@inproceedings{northAnalytic2011,
  location = {{New York, NY, USA}},
  title = {Analytic {{Provenance}}: {{Process}}+{{Interaction}}+{{Insight}}},
  isbn = {978-1-4503-0268-5},
  url = {http://doi.acm.org/10.1145/1979742.1979570},
  doi = {10.1145/1979742.1979570},
  shorttitle = {Analytic {{Provenance}}},
  timestamp = {2016-01-26T01:30:05Z},
  booktitle = {{{CHI}} '11 {{Extended Abstracts}} on {{Human Factors}} in {{Computing Systems}}},
  series = {CHI EA '11},
  publisher = {{ACM}},
  author = {North, Chris and Chang, Remco and Endert, Alex and Dou, Wenwen and May, Richard and Pike, Bill and Fink, Glenn},
  urldate = {2016-01-26},
  date = {2011},
  pages = {33--36},
  keywords = {analytic provenance,User Interaction,Visual analytics,Visualization}
}

@article{rothInteractive2013,
  title = {Interactive maps: {{What}} we know and what we need to know},
  volume = {2013},
  issn = {1948-660X},
  url = {http://josis.org/index.php/josis/article/view/105},
  doi = {10.5311/JOSIS.2013.6.105},
  shorttitle = {Interactive maps},
  abstract = {Interactive maps: What we know and what we need to know},
  timestamp = {2016-01-26T01:29:28Z},
  number = {6},
  journaltitle = {Journal of Spatial Information Science},
  shortjournal = {J. Spat. Inf. Sci.},
  author = {Roth, Robert E.},
  urldate = {2016-01-26},
  date = {2013-06-15},
  pages = {59--115},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/GG5UPFQX/105.html:;Full Text PDF:/Users/ben/Documents/zotero/storage/RBX8ZDWQ/Roth - 2013 - Interactive maps What we know and what we need to.pdf:application/pdf}
}

@article{endertSemantic2012,
  title = {Semantic {{Interaction}} for {{Sensemaking}}: {{Inferring Analytical Reasoning}} for {{Model Steering}}},
  volume = {18},
  issn = {1077-2626},
  doi = {10.1109/TVCG.2012.260},
  shorttitle = {Semantic {{Interaction}} for {{Sensemaking}}},
  abstract = {Visual analytic tools aim to support the cognitively demanding task of sensemaking. Their success often depends on the ability to leverage capabilities of mathematical models, visualization, and human intuition through flexible, usable, and expressive interactions. Spatially clustering data is one effective metaphor for users to explore similarity and relationships between information, adjusting the weighting of dimensions or characteristics of the dataset to observe the change in the spatial layout. Semantic interaction is an approach to user interaction in such spatializations that couples these parametric modifications of the clustering model with users' analytic operations on the data (e.g., direct document movement in the spatialization, highlighting text, search, etc.). In this paper, we present results of a user study exploring the ability of semantic interaction in a visual analytic prototype, ForceSPIRE, to support sensemaking. We found that semantic interaction captures the analytical reasoning of the user through keyword weighting, and aids the user in co-creating a spatialization based on the user's reasoning and intuition.},
  timestamp = {2016-01-26T01:28:48Z},
  number = {12},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  shortjournal = {IEEE Trans. Vis. Comput. Graph.},
  author = {Endert, A. and Fiaux, P. and North, C.},
  date = {2012-12},
  pages = {2879--2888},
  keywords = {Analytical models,analytical reasoning,analytic reasoning,clustering model,cognitively demanding task,data visualisation,expressive interactions,ForceSPIRE,human intuition,inference mechanisms,keyword weighting,Mathematical model,Mathematical models,model steering,parametric modifications,semantic interaction,SEMANTICS,sensemaking,spatially clustering data,User Interaction,user interfaces,visual analytic prototype,Visual analytics,visual analytic tools,Visualization},
  file = {IEEE Xplore Abstract Record:/Users/ben/Documents/zotero/storage/JFUF5TF4/abs_all.html:;IEEE Xplore Full Text PDF:/Users/ben/Documents/zotero/storage/NI5UWWGD/Endert et al. - 2012 - Semantic Interaction for Sensemaking Inferring An.pdf:application/pdf}
}

@article{elmqvistFluid2011,
  title = {Fluid interaction for information visualization},
  volume = {10},
  issn = {1473-8716, 1473-8724},
  url = {http://ivi.sagepub.com.virtual.anu.edu.au/content/10/4/327},
  doi = {10.1177/1473871611413180},
  abstract = {Despite typically receiving little emphasis in visualization research, interaction in visualization is the catalyst for the user's dialogue with the data, and, ultimately, the user's actual understanding and insight into these data. There are many possible reasons for this skewed balance between the visual and interactive aspects of a visualization. One reason is that interaction is an intangible concept that is difficult to design, quantify, and evaluate. Unlike for visual design, there are few examples that show visualization practitioners and researchers how to design the interaction for a new visualization in the best manner. In this article, we attempt to address this issue by collecting examples of visualizations with ‘best-in-class’ interaction and using them to extract practical design guidelines for future designers and researchers. We call this concept fluid interaction, and we propose an operational definition in terms of the direct manipulation and embodied interaction paradigms, the psychological concept of ‘flow’, and Norman's gulfs of execution and evaluation.},
  timestamp = {2016-01-26T01:28:02Z},
  langid = {english},
  number = {4},
  journaltitle = {Information Visualization},
  shortjournal = {Information Visualization},
  author = {Elmqvist, Niklas and Moere, Andrew Vande and Jetter, Hans-Christian and Cernea, Daniel and Reiterer, Harald and Jankun-Kelly, T. J.},
  urldate = {2016-01-26},
  date = {2011-10-01},
  pages = {327--340},
  keywords = {design,embodiment,flow,fluidity,human--computer interaction,information visualization},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/BTP2RVQP/327.html:;Full Text PDF:/Users/ben/Documents/zotero/storage/IGPRDBF4/Elmqvist et al. - 2011 - Fluid interaction for information visualization.pdf:application/pdf}
}

@article{pikeScience2009,
  title = {The {{Science}} of {{Interaction}}},
  volume = {8},
  issn = {1473-8716, 1473-8724},
  url = {http://ivi.sagepub.com.virtual.anu.edu.au/content/8/4/263},
  doi = {10.1057/ivs.2009.22},
  abstract = {There is a growing recognition within the visual analytics community that interaction and inquiry are inextricable. It is through the interactive manipulation of a visual interface-the analytic discourse-that knowledge is constructed, tested, refined and shared. This article reflects on the interaction challenges raised in the visual analytics research and development agenda and further explores the relationship between interaction and cognition. It identifies recent exemplars of visual analytics research that have made substantive progress toward the goals of a true science of interaction, which must include theories and testable premises about the most appropriate mechanisms for human-information interaction. Seven areas for further work are highlighted as those among the highest priorities for the next 5 years of visual analytics research: ubiquitous, embodied interaction; capturing user intentionality; knowledge-based interfaces; collaboration; principles of design and perception; interoperability; and interaction evaluation. Ultimately, the goal of a science of interaction is to support the visual analytics and human-computer interaction communities through the recognition and implementation of best practices in the representation and manipulation of visual displays.},
  timestamp = {2016-01-26T01:26:35Z},
  langid = {english},
  number = {4},
  journaltitle = {Information Visualization},
  journal = {Information Visualization},
  year= {2009},
  shortjournal = {Information Visualization},
  author = {Pike, William A. and Stasko, John and Chang, Remco and O'Connell, Theresa A.},
  urldate = {2016-01-26},
  date = {2009-12-21},
  pages = {263--274},
  keywords = {Collaboration,interaction theory,reasoning,Visual analytics},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/FMJAQFQR/263.html:;Full Text PDF:/Users/ben/Documents/zotero/storage/JGQ789VH/Pike et al. - 2009 - The Science of Interaction.pdf:application/pdf}
}

@article{staskojigsaw2008,
  title = {Jigsaw: {{Supporting Investigative Analysis}} through {{Interactive Visualization}}},
  volume = {7},
  issn = {1473-8716, 1473-8724},
  url = {http://ivi.sagepub.com.virtual.anu.edu.au/content/7/2/118},
  doi = {10.1057/palgrave.ivs.9500180},
  shorttitle = {Jigsaw},
  abstract = {Investigative analysts who work with collections of text documents connect embedded threads of evidence in order to formulate hypotheses about plans and activities of potential interest. As the number of documents and the corresponding number of concepts and entities within the documents grow larger, sense-making processes become more and more difficult for the analysts. We have developed a visual analytic system called Jigsaw that represents documents and their entities visually in order to help analysts examine them more efficiently and develop theories about potential actions more quickly. Jigsaw provides multiple coordinated views of document entities with a special emphasis on visually illustrating connections between entities across the different documents.},
  timestamp = {2016-01-26T01:26:09Z},
  langid = {english},
  number = {2},
  journaltitle = {Information Visualization},
  shortjournal = {Information Visualization},
  author = {Stasko, John and Görg, Carsten and Liu, Zhicheng},
  urldate = {2016-01-26},
  date = {2008-06-20},
  pages = {118--132},
  keywords = {information visualization,intelligence analysis,investigative analysis,multiple views,sense-making,Visual analytics},
  file = {Full Text PDF:/Users/ben/Documents/zotero/storage/AAR86KZE/Stasko et al. - 2008 - Jigsaw Supporting Investigative Analysis through .pdf:application/pdf;Snapshot:/Users/ben/Documents/zotero/storage/ICMK4HZ9/118.html:}
}

@article{yideeper2007,
  title = {Toward a {{Deeper Understanding}} of the {{Role}} of {{Interaction}} in {{Information Visualization}}},
  volume = {13},
  issn = {1077-2626},
  doi = {10.1109/TVCG.2007.70515},
  abstract = {Even though interaction is an important part of information visualization (Infovis), it has garnered a relatively low level of attention from the Infovis community. A few frameworks and taxonomies of Infovis interaction techniques exist, but they typically focus on low-level operations and do not address the variety of benefits interaction provides. After conducting an extensive review of Infovis systems and their interactive capabilities, we propose seven general categories of interaction techniques widely used in Infovis: 1) Select, 2) Explore, 3) Reconfigure, 4) Encode, 5) Abstract/Elaborate, 6) Filter, and 7) Connect. These categories are organized around a user's intent while interacting with a system rather than the low-level interaction techniques provided by a system. The categories can act as a framework to help discuss and evaluate interaction techniques and hopefully lay an initial foundation toward a deeper understanding and a science of interaction.},
  timestamp = {2016-01-26T01:22:29Z},
  number = {6},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  shortjournal = {IEEE Trans. Vis. Comput. Graph.},
  author = {Yi, Ji Soo and ah Kang, Youn and Stasko, J.T. and Jacko, J.A.},
  date = {2007-11},
  pages = {1224--1231},
  keywords = {Computer displays,Computer Graphics,Conference proceedings,data visualisation,Data visualization,Filters,human computer interaction,information visualization,Infovis community,Infovis interaction techniques,Infovis systems,Interaction,Interaction Techniques,Rendering (computer graphics),Research and development,taxonomy,Visual analytics},
  file = {IEEE Xplore Abstract Record:/Users/ben/Documents/zotero/storage/ADB5MEAH/abs_all.html:;IEEE Xplore Full Text PDF:/Users/ben/Documents/zotero/storage/VUP6VIVM/Yi et al. - 2007 - Toward a Deeper Understanding of the Role of Inter.pdf:application/pdf}
}


@article{guyonnethybrid2003,
  title = {Hybrid approach for addressing uncertainty in risk assessments},
  volume = {129},
  timestamp = {2016-02-01T08:22:11Z},
  number = {1},
  journaltitle = {Journal of Environmental Engineering},
  shortjournal = {J. Environ. Eng.},
  author = {Guyonnet, Dominique and Bourgine, Bernard and Dubois, Didier and Fargier, Hélène and Côme, Bernard and Chilès, Jean-Paul},
  date = {2003},
  pages = {68--78},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/FXUBJPK2/(ASCE)0733-9372(2003)1291(68).html:;Guyonnet journal.pdf:/Users/ben/Documents/zotero/storage/WRWF7GBS/Guyonnet journal.pdf:application/pdf}
}


@article{dasguptaconceptualizing2012,
  title = {Conceptualizing {{Visual Uncertainty}} in {{Parallel Coordinates}}},
  volume = {31},
  issn = {1467-8659},
  url = {http://onlinelibrary.wiley.com.virtual.anu.edu.au/doi/10.1111/j.1467-8659.2012.03094.x/abstract},
  doi = {10.1111/j.1467-8659.2012.03094.x},
  abstract = {Uncertainty is an intrinsic part of any visual representation in visualization, no matter how precise the input data. Existing research on uncertainty in visualization mainly focuses on depicting data-space uncertainty in a visual form. Uncertainty is thus often seen as a problem to deal with, in the data, and something to be avoided if possible. In this paper, we highlight the need for analyzing visual uncertainty in order to design more effective visual representations. We study various forms of uncertainty in the visual representation of parallel coordinates and propose a taxonomy for categorizing them. By building a taxonomy, we aim to identify different sources of uncertainty in the screen space and relate them to different effects of uncertainty upon the user. We examine the literature on parallel coordinates and apply our taxonomy to categorize various techniques for reducing uncertainty. In addition, we consider uncertainty from a different perspective by identifying cases where increasing certain forms of uncertainty may even be useful, with respect to task, data type and analysis scenario. This work suggests that uncertainty is a feature that can be both useful and problematic in visualization, and it is beneficial to augment an information visualization pipeline with a facility for visual uncertainty analysis.},
  timestamp = {2016-01-25T04:19:51Z},
  langid = {english},
  number = {3pt2},
  journaltitle = {Computer Graphics Forum},
  shortjournal = {Comput. Graph. Forum},
  author = {Dasgupta, Aritra and Chen, Min and Kosara, Robert},
  urldate = {2016-01-25},
  date = {2012-06-01},
  pages = {1015--1024},
  file = {Full Text PDF:/Users/ben/Documents/zotero/storage/452TDW6B/Dasgupta et al. - 2012 - Conceptualizing Visual Uncertainty in Parallel Coo.pdf:application/pdf;Snapshot:/Users/ben/Documents/zotero/storage/IGBDFNIJ/abstract.html:}
}

@inproceedings{fuahierarchical1999,
  location = {{Los Alamitos, CA, USA}},
  title = {Hierarchical {{Parallel Coordinates}} for {{Exploration}} of {{Large Datasets}}},
  isbn = {978-0-7803-5897-3},
  url = {http://dl.acm.org/citation.cfm?id=319351.319355},
  abstract = {Our ability to accumulate large, complex (multivariate) data sets has far exceeded our ability to effectively process them in search of patterns, anomalies, and other interesting features. Conventional multivariate visualization techniques generally do not scale well with respect to the size of the data set. The focus of this paper is on the interactive visualization of large multivariate data sets based on a number of novel extensions to the parallel coordinates display technique. We develop a multiresolutional view of the data via hierarchical clustering, and use a variation on parallel coordinates to convey aggregation information for the resulting clusters. Users can then navigate the resulting structure until the desired focus region and level of detail is reached, using our suite of navigational and filtering tools. We describe the design and implementation of our hierarchical parallel coordinates system which is based on extending the XmdvTool system. Lastly, we show examples of the tools and techniques applied to large (hundreds of thousands of records) multivariate data sets.},
  timestamp = {2016-01-25T04:18:27Z},
  booktitle = {Proceedings of the {{Conference}} on {{Visualization}} '99: {{Celebrating Ten Years}}},
  series = {VIS '99},
  publisher = {{IEEE Computer Society Press}},
  author = {Fua, Ying-Huey and Ward, Matthew O. and Rundensteiner, Elke A.},
  urldate = {2016-01-25},
  date = {1999},
  pages = {43--50},
  keywords = {hierarchical data exploration,large-scale multivariate data visualization,Parallel coordinates}
}

@inproceedings{luovisualizing2003,
  location = {{Aire-la-Ville, Switzerland, Switzerland}},
  title = {Visualizing {{Spatial Distribution Data Sets}}},
  isbn = {978-1-58113-698-2},
  url = {http://dl.acm.org/citation.cfm?id=769922.769925},
  abstract = {In this paper, we define distributions as a new data type and address the challenges of visualizing spatial distribution data sets. Numerous visualization techniques exist today for dealing with scalar data. That is, there is a scalar value at each spatial location, which may also be changing over time. Likewise, techniques exist for dealing with vector, tensor and multivariate data sets. However, there is currently no systematic way of dealing with distribution data where there is a collection of values for the same variable at every location and time. Distribution data is increasingly becoming more common as computers and sensor technologies continue to improve. They have also been used in a number of fields ranging from agriculture, engineering design and manufacturing to weather forecasting. Rather than developing specialized visualization techniques for dealing with distribution data, the approach presented in this paper is to find a systematic way of extending existing visualization methods to handle this new data type. For example, we would like to be able to generate isosurfaces of 3D scalar distribution data sets, or generate streamlines of vector distribution data sets. In order to accomplish this goal, we propose the use of a set of mathematically and procedurally defined operators that allow us to work directly on distributions. Color images can also be found in www.cse.ucsc.edu/research/avis/operator.html.},
  timestamp = {2016-01-25T04:07:57Z},
  booktitle = {Proceedings of the {{Symposium}} on {{Data Visualisation}} 2003},
  series = {VISSYM '03},
  publisher = {{Eurographics Association}},
  author = {Luo, Alison and Kao, David and Pang, Alex},
  urldate = {2016-01-25},
  date = {2003},
  pages = {29--38},
  file = {op.pdf:/Users/ben/Documents/zotero/storage/5KFZF9EW/op.pdf:application/pdf}
}

@article{roloffprocess2005,
  title = {A process for modeling short- and long-term risk in the southern {{Oregon Cascades}}},
  volume = {211},
  issn = {0378-1127},
  url = {http://www.sciencedirect.com/science/article/pii/S0378112705000617},
  doi = {10.1016/j.foreco.2005.02.006},
  abstract = {Evaluating tradeoffs between the short- and long-term risks of different management scenarios in fire prone ecosystems is crucial to implementation of the National Fire Plan and the Healthy Forest Restoration Act (H.R. 1904). We demonstrate a process for conducting these relative risk assessments using models and data generally available via the public domain. Our risk assessment process integrates information about the ecological characteristics of the landscape, vegetation dynamics as related to different management scenarios, and fire modeling, to generate inputs for effects analyses on water temperature, peak flows, landslides, and northern spotted owls (Strix occidentalis caurina). The process is demonstrated for current management with owl foraging emphasis and no management scenarios in a 325,000 ha landscape in southwestern Oregon. The current management with owl foraging emphasis scenario represents a reasonable portrayal of current land management policies and allocations with an emphasis on providing spotted owl foraging habitat across the landscape. The no management scenario portrays only vegetation dynamics as projected by a growth and yield model. Results from both management scenarios were subjected to fire and effects modeling. Simulation results indicated that risk metrics used in this demonstration were sensitive to the manner in which we described and attributed the landscape and our model formulations and thus, were useful measures for relative risk assessments. Model simulations demonstrated that the potential for uncharacteristic fire increased five-fold within the first 20 years under both management scenarios. The area burned by crown fire and uncharacteristic fire also increased over time for both management scenarios. Both management scenarios resulted in a decline of spotted owl habitat, with the current management with owl foraging emphasis scenario creating more unfavorable conditions. We attribute the relatively high long-term risk of the current management with owl foraging emphasis scenario to a combination of the large-scale passive management approach instituted on a substantial portion of the landscape (approximately 55\% of the assessment area), the presence of plantation-based forestry (approximately 22\% of the area), and by default, the limited opportunity to implement hazardous fuels reduction at a scale large enough to influence landscape-level fuel patterns. These preliminary results suggest that a spatially explicit, more aggressive hazardous fuels reduction management scenario, that may conflict with current land management policies and allocations, is needed to reduce the continuity of hazardous fuels and sustain healthy forest conditions and spotted owl habitat.},
  timestamp = {2016-01-25T04:03:49Z},
  number = {1--2},
  journaltitle = {Forest Ecology and Management},
  shortjournal = {Forest Ecology and Management},
  series = {Relative Risk Assessments for Decision --Making Related To Uncharacteristic WildfireRelative Risk Assessments for Decision --Making Related To Uncharacteristic Wildfire},
  author = {Roloff, Gary J. and Mealey, Stephen P. and Clay, Christopher and Barry, Jeff and Yanish, Curt and Neuenschwander, Leon},
  urldate = {2016-01-25},
  date = {2005-06-06},
  pages = {166--190},
  keywords = {FARSITE,Fire effects,Fire Modeling,FlamMap,Forest planning,Fuel treatment,Hazardous fuels reduction,Historical fire regime,Hydrologic modeling,Ignition probability,Landscape analysis,Landslides,Plant associations,Relative risk assessment,Restoration,Risk,simulation,Spotted owls,Uncharacteristic fire},
  file = {ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/9VF543E5/S0378112705000617.html:;ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/DJI5CGF9/Roloff et al. - 2005 - A process for modeling short- and long-term risk i.pdf:application/pdf}
}

@article{maceachrenvisualizing1992,
  title = {Visualizing {{Uncertain Information}}},
  volume = {0},
  rights = {Authors who publish with this journal agree to the following terms:     Authors retain copyright and grant the journal right of first publication, with the work simultaneously licensed under a~ Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.   Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.   Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See~ The Effect of Open Access ).},
  issn = {1048-9053},
  url = {http://www.cartographicperspectives.org/index.php/journal/article/view/cp13-maceachren},
  doi = {10.14714/CP13.1000},
  abstract = {When a GIS is used to drive map-based visualization, exploration of potential relationships takes precedence over presentation of facts. In these early stages of scientific analysis or policy formulation, providing a way for analysts to assess uncertainty in the data they are exploring is critical to the perspectives they form and the approaches they decide to pursue. As a basis from which to develop methods for visualizing uncertain information, this paper addresses the difference between data quality and uncertainty, the application of Berlin's graphic variables to the representation of uncertainty, conceptual models of spatial uncertainty as they relate to kinds of cartographic symbolization, and categories of user interfaces suited to presenting data and uncertainty about that data. Also touched on is the issue of how we might evaluate our attempts to depict uncertain information on maps.},
  timestamp = {2016-01-25T04:01:58Z},
  langid = {english},
  number = {13},
  journaltitle = {Cartographic Perspectives},
  shortjournal = {Cartogr. Perspect.},
  author = {MacEachren, Alan M.},
  urldate = {2016-01-25},
  date = {1992-06-01},
  pages = {10--19},
  keywords = {information,Uncertainty,Visualization},
  file = {Full Text PDF:/Users/ben/Documents/zotero/storage/PHDTJKDV/MacEachren - 1992 - Visualizing Uncertain Information.pdf:application/pdf;Snapshot:/Users/ben/Documents/zotero/storage/ZJZTSX6V/1000.html:}
}

@article{thompsonSocial2014,
  title = {Social, {{Institutional}}, and {{Psychological Factors Affecting Wildfire Incident Decision Making}}},
  volume = {27},
  issn = {0894-1920},
  url = {http://dx.doi.org/10.1080/08941920.2014.901460},
  doi = {10.1080/08941920.2014.901460},
  abstract = {Managing wildland fire incidents can be fraught with complexity and uncertainty. Myriad human factors can exert significant influence on incident decision making, and can contribute additional uncertainty regarding programmatic evaluations of wildfire management and attainment of policy goals. This article develops a framework within which human sources of uncertainty in wildfire management can be classified and managed, specifically identifying social, institutional, and psychological factors that can affect wildland fire incident decision making. These factors are reviewed in the context of wildland fire incident management and the literature regarding fire manager decision making. I then provide specific recommendations for addressing these issues, with a focus on improving incident decision processes. Extending this framework to consider a broader set of human factors and to consider how human factors affect the broader wildfire management spectrum could lead to improved fire management outcomes.},
  timestamp = {2016-01-25T02:49:44Z},
  number = {6},
  journaltitle = {Society \& Natural Resources},
  journal = {Society \& Natural Resources},
  year={2014},
  shortjournal = {Soc. Nat. Resour.},
  author = {Thompson, Matthew P.},
  urldate = {2016-01-25},
  date = {2014-06-01},
  pages = {636--644},
  file = {Full Text PDF:/Users/ben/Documents/zotero/storage/4TM4HFQW/Thompson - 2014 - Social, Institutional, and Psychological Factors A.pdf:application/pdf;Snapshot:/Users/ben/Documents/zotero/storage/NRFEWBCS/08941920.2014.html:}
}

@article{thompsonuncertainty2011,
  title = {Uncertainty and risk in wildland fire management: {{A}} review},
  volume = {92},
  issn = {0301-4797},
  url = {http://www.sciencedirect.com/science/article/pii/S0301479711000818},
  doi = {10.1016/j.jenvman.2011.03.015},
  shorttitle = {Uncertainty and risk in wildland fire management},
  abstract = {Wildland fire management is subject to manifold sources of uncertainty. Beyond the unpredictability of wildfire behavior, uncertainty stems from inaccurate/missing data, limited resource value measures to guide prioritization across fires and resources at risk, and an incomplete scientific understanding of ecological response to fire, of fire behavior response to treatments, and of spatiotemporal dynamics involving disturbance regimes and climate change. This work attempts to systematically align sources of uncertainty with the most appropriate decision support methodologies, in order to facilitate cost-effective, risk-based wildfire planning efforts. We review the state of wildfire risk assessment and management, with a specific focus on uncertainties challenging implementation of integrated risk assessments that consider a suite of human and ecological values. Recent advances in wildfire simulation and geospatial mapping of highly valued resources have enabled robust risk-based analyses to inform planning across a variety of scales, although improvements are needed in fire behavior and ignition occurrence models. A key remaining challenge is a better characterization of non-market resources at risk, both in terms of their response to fire and how society values those resources. Our findings echo earlier literature identifying wildfire effects analysis and value uncertainty as the primary challenges to integrated wildfire risk assessment and wildfire management. We stress the importance of identifying and characterizing uncertainties in order to better quantify and manage them. Leveraging the most appropriate decision support tools can facilitate wildfire risk assessment and ideally improve decision-making.},
  timestamp = {2016-01-25T01:05:59Z},
  number = {8},
  journaltitle = {Journal of Environmental Management},
  shortjournal = {Journal of Environmental Management},
  author = {Thompson, Matthew P. and Calkin, Dave E.},
  urldate = {2016-01-25},
  date = {2011-08},
  pages = {1895--1909},
  keywords = {decision support,risk assessment,Uncertainty and risk,Wildfire management},
  file = {ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/C5IIA3DW/S0301479711000818.html:;ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/JW633KQW/Thompson and Calkin - 2011 - Uncertainty and risk in wildland fire management .pdf:application/pdf}
}

@article{hiltoneffects2015,
  title = {Effects of spatial and temporal variation in environmental conditions on simulation of wildfire spread},
  volume = {67},
  issn = {1364-8152},
  url = {http://www.sciencedirect.com/science/article/pii/S1364815215000468},
  doi = {10.1016/j.envsoft.2015.01.015},
  abstract = {Environmental conditions, such as fuel load and moisture levels, can influence the behaviour of wildfires. These factors are subject to natural small-scale variation which is usually spatially or temporally averaged for modelling fire propagation. The effect of including this variation in propagation models has not previously been fully examined or quantified. We investigate the effects of incorporating three types of variation on the shape and rate of propagation of a fire perimeter: variation in combustion conditions, wind direction and wind speed. We find that increasing the variation of combustion condition decreases the overall rate of propagation. An analytical model, based on the harmonic mean, is presented to explain this behaviour. Variation in wind direction is found to cause the development of rounded flanks due to cumulative chance of outward fluctuations at the sides of the perimeter. Our findings may be used to develop improved models for fire spread prediction.},
  timestamp = {2016-01-25T00:59:41Z},
  journaltitle = {Environmental Modelling \& Software},
  shortjournal = {Environmental Modelling \& Software},
  author = {Hilton, J. E. and Miller, C. and Sullivan, A. L. and Rucinski, C.},
  urldate = {2016-01-25},
  date = {2015-05},
  pages = {118--127},
  keywords = {Fire growth,Level set,modelling,Perimeter propagation,simulation,Spark},
  file = {ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/GWHFAZDZ/Hilton et al. - 2015 - Effects of spatial and temporal variation in envir.pdf:application/pdf;ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/NQWA46EJ/S1364815215000468.html:}
}

@article{greeninteractive1990,
  title = {Interactive simulation of bushfires in heterogeneous fuels},
  volume = {13},
  issn = {0895-7177},
  url = {http://www.sciencedirect.com/science/article/pii/0895717790900999},
  doi = {10.1016/0895-7177(90)90099-9},
  abstract = {The program IGNITE, developed by the authors, is a landscape fire modelling system that deals with fires in heterogeneous fuels. Landscapes are represented as cellular automata (grids of pixels) and fire spread is modelled as an epidemic process. An integrated geographic information system permits the importing and editing of maps from compatible sources, such as satellite imagery. Maps, models and other information are organized as scenarios; historical fires can be recorded and replayed. Modules are being developed for application to fire prevention, fire suppression, land-use management, and to training and education. An illustration of using the system to deal with heterogeneous fuel is its application to the problem of percolation in patchy fuel.},
  timestamp = {2016-01-25T00:58:47Z},
  number = {12},
  journaltitle = {Mathematical and Computer Modelling},
  shortjournal = {Mathematical and Computer Modelling},
  author = {Green, David G. and Tridgell, Andrew and Gill, A. Malcolm},
  urldate = {2016-01-25},
  date = {1990},
  pages = {57--66},
  file = {ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/9ZFVJDFA/0895717790900999.html:;ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/F5DGMSE6/Green et al. - 1990 - Interactive simulation of bushfires in heterogeneo.pdf:application/pdf}
}

@article{winkworthcommunity2009,
  title = {Community {{Capacity Building}}: {{Learning}} from the 2003 {{Canberra Bushfires}}},
  volume = {24},
  url = {http://search.informit.com.au/documentSummary;dn=870116212372793;res=IELHSS},
  shorttitle = {Community {{Capacity Building}}},
  abstract = {Research into what happens to communities after disasters is one way of understanding the elements of community capacity building and the actions that help and hinder these processes. In recent years a number of large scale disasters both onshore and offshore have become the focus of Australian State and Commonwealth disaster recovery efforts. These have provided opportunities to reflect on successful elements of 'community recovery' including what 'communities' do themselves to assist 'recovery' and what governments can do to enable and actively facilitate the 'recovery' process. Through an examination of a recent study on the recovery of people affected by the Australian Capital Territory (ACT) bushfires (known as the Canberra Bushfires) (Camilleri et al, 2007), this paper examines what helps and what hinders community capacity building, including the role of social networks and supports and community engagement activities. It also contributes to a broader knowledge base about the importance of governments recognising and enabling the development of social networks which help people 'get by', and 'get ahead', and which foster a sense of control over their lives. This knowledge can usefully frame actions used in the pursuit of many other desired policy outcomes linked to community capacity building.},
  timestamp = {2016-01-25T00:57:52Z},
  number = {2},
  journaltitle = {Australian Journal of Emergency Management, The},
  shortjournal = {Aust. J. Emerg. Manag.},
  author = {Winkworth, Gail and Healy, Chris and Woodward, Merrilyn and Camilleri, Peter},
  urldate = {2016-01-25},
  date = {2009-05},
  pages = {5},
  file = {AJEM-24-02-03.pdf:/Users/ben/Documents/zotero/storage/KM5A5CMD/AJEM-24-02-03.pdf:application/pdf}
}

@article{rodriguez-rinconpropagation2015,
  title = {Propagation of hydro-meteorological uncertainty in a model cascade framework to inundation prediction},
  volume = {19},
  timestamp = {2016-01-22T00:45:42Z},
  number = {7},
  journaltitle = {Hydrology and Earth System Sciences},
  shortjournal = {Hydrol. Earth Syst. Sci.},
  author = {Rodríguez-Rincón, J. P. and Pedrozo-Acuña, A. and Breña-Naranjo, J. A.},
  date = {2015},
  pages = {2981--2998},
  file = {hess-2014-246-Final.pdf:/Users/ben/Documents/zotero/storage/P468H74G/hess-2014-246-Final.pdf:application/pdf}
}

@article{nealeScientific,
  title = {{{SCIENTIFIC KNOWLEDGE AND SCIENTIFIC UNCERTAINTY IN BUSHFIRE AND FLOOD RISK MITIGATION}}},
  timestamp = {2016-01-22T00:43:38Z},
  author = {Neale, Timothy},
  file = {RMPP_ScientificKnowledge_LitReview2015.pdf:/Users/ben/Documents/zotero/storage/G5FT355M/RMPP_ScientificKnowledge_LitReview2015.pdf:application/pdf}
}

@article{vandenhonert_20112011,
  title = {The 2011 {{Brisbane Floods}}: {{Causes}}, {{Impacts}} and {{Implications}}},
  volume = {3},
  rights = {http://creativecommons.org/licenses/by/3.0/},
  url = {http://www.mdpi.com/2073-4441/3/4/1149},
  doi = {10.3390/w3041149},
  shorttitle = {The 2011 {{Brisbane Floods}}},
  abstract = {On 13th January 2011 major flooding occurred throughout most of the Brisbane River catchment, most severely in Toowoomba and the Lockyer Creek catchment (where 23 people drowned), the Bremer River catchment and in Brisbane, the state capital of Queensland. Some 56,200 claims have been received by insurers with payouts totalling {\textdollar}2.55 billion. This paper backgrounds weather and climatic factors implicated in the flooding and the historical flood experience of Brisbane. We examine the time history of water releases from the Wivenhoe dam, which have been accused of aggravating damage downstream. The dam was built in response to even worse flooding in 1974 and now serves as Brisbane’s main water supply. In our analysis, the dam operators made sub-optimal decisions by neglecting forecasts of further rainfall and assuming a ‘no rainfall’ scenario. Questions have also been raised about the availability of insurance cover for riverine flood, and the Queensland government’s decision not to insure its infrastructure. These and other questions have led to Federal and State government inquiries. We argue that insurance is a form of risk transfer for the residual risk following risk management efforts and cannot in itself be a solution for poor land-use planning. With this in mind, we discuss the need for risk-related insurance premiums to encourage flood risk mitigating behaviours by all actors, and for transparency in the availability of flood maps. Examples of good flood risk management to arise from this flood are described.},
  timestamp = {2016-01-22T00:12:53Z},
  langid = {english},
  number = {4},
  journaltitle = {Water},
  shortjournal = {Water},
  author = {van den Honert, Robin C. and McAneney, John},
  urldate = {2016-01-22},
  date = {2011-12-09},
  pages = {1149--1173},
  keywords = {Brisbane River,flood,flood risk management,insurance,January 2011,land use planning,water release strategy},
  options = {useprefix=true},
  file = {Full Text PDF:/Users/ben/Documents/zotero/storage/6HXIMEK4/van den Honert and McAneney - 2011 - The 2011 Brisbane Floods Causes, Impacts and Impl.pdf:application/pdf;Snapshot:/Users/ben/Documents/zotero/storage/ZCIK54AI/1149.html:}
}

@article{yinrealtime2014,
  title = {Real-{{Time Implementation}} of {{Fault-Tolerant Control Systems With Performance Optimization}}},
  volume = {61},
  issn = {0278-0046},
  doi = {10.1109/TIE.2013.2273477},
  abstract = {In this paper, two online schemes for an integrated design of fault-tolerant control (FTC) systems with application to Tennessee Eastman (TE) benchmark are proposed. Based on the data-driven design of the proposed fault-tolerant architecture whose core is an observer/residual generator based realization of the Youla parameterization of all stabilization controllers, FTC is achieved by an adaptive residual generator for the online identification of the fault diagnosis relevant vectors, and an iterative optimization method for system performance enhancement. The performance and effectiveness of the proposed schemes are demonstrated through the TE benchmark model.},
  timestamp = {2016-01-21T00:34:05Z},
  number = {5},
  journaltitle = {IEEE Transactions on Industrial Electronics},
  shortjournal = {IEEE Trans. Ind. Electron.},
  author = {Yin, Shen and Luo, Hao and Ding, S.X.},
  date = {2014-05},
  pages = {2402--2411},
  keywords = {adaptive control,adaptive residual generator,Adaptive system,fault diagnosis,fault tolerance,fault-tolerant architecture,fault-tolerant control (FTC),fault-tolerant control systems,Fault tolerant systems,Generators,integrated design,iterative methods,observer-residual generator based realization,observers,online identification,optimisation,Optimization,performance optimization,real-time implementation,signal processing,stability,stabilization controllers,System performance,TE benchmark model,Tennessee Eastman benchmark,Vectors,Youla parameterization},
  file = {IEEE Xplore Full Text PDF:/Users/ben/Documents/zotero/storage/FJJHTJRW/Yin et al. - 2014 - Real-Time Implementation of Fault-Tolerant Control.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/ben/Documents/zotero/storage/JE72T9TN/absall.html:}
}

@article{obriencrisis2010,
  title = {Crisis {{Early Warning}} and {{Decision Support}}: {{Contemporary Approaches}} and {{Thoughts}} on {{Future Research}}},
  volume = {12},
  rights = {© 2010 International Studies Association},
  issn = {1468-2486},
  url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1468-2486.2009.00914.x/abstract},
  doi = {10.1111/j.1468-2486.2009.00914.x},
  shorttitle = {Crisis {{Early Warning}} and {{Decision Support}}},
  abstract = {Military planners and other decision makers require advanced early warning of impending crises so they can devise effective mitigation plans, mobilize resources, and coordinate responses with their foreign counterparts. Over the last 40~years, the US government has invested generously in several attempts to build crisis forecasting systems that were analytically defensible and capable of processing and making sense of vast amounts of information in real or near real time. This article describes the most recent attempt by the US military to develop an Integrated Crisis Early Warning System (ICEWS). Although ICEWS relies heavily on social science theories, data, and methods, our experiences thus far reveal some strengths and limitations of contemporary quantitative approaches to addressing social science questions with real world implications. The article concludes with a sketch of a new paradigmatic approach—a Computational Social Science Experimentation Proving Ground—that could not only improve crisis early warning and response, but also revolutionize how social science knowledge is developed, evaluated, and applied more broadly.},
  timestamp = {2016-01-20T23:47:38Z},
  langid = {english},
  number = {1},
  journaltitle = {International Studies Review},
  shortjournal = {Int. Stud. Rev.},
  author = {O’Brien, Sean P.},
  urldate = {2016-01-20},
  date = {2010-03-01},
  pages = {87--104},
  file = {Full Text PDF:/Users/ben/Documents/zotero/storage/AJ3B39SU/O’Brien - 2010 - Crisis Early Warning and Decision Support Contemp.pdf:application/pdf;Snapshot:/Users/ben/Documents/zotero/storage/JM9SNXJA/abstract.html:}
}

@article{kaloudisassessing2005,
  title = {Assessing {{Wildfire Destruction Danger}}: a {{Decision Support System Incorporating Uncertainty}}},
  volume = {181},
  issn = {0304-3800},
  url = {http://www.sciencedirect.com/science/article/pii/S0304380004003564},
  doi = {10.1016/j.ecolmodel.2004.06.021},
  shorttitle = {Assessing {{Wildfire Destruction Danger}}},
  abstract = {A composite index is proposed for fire destruction danger assessment. Wildfire incidence and fire severity (FS), in association with the values in threat and the sensitivity of these values to fire, are some of its constituent parameters. The index is computed by use of logic programming within a multi-criteria Decision Support System (DSS). It is applicable to either large or small areas and can be used for short and long-term prediction. The Decision Support System is also described along with the underlying reasoning assumptions. It incorporates mechanisms for the representation and handling of uncertainty and can reason with inexact or incomplete information. The building blocks of its architecture consist of hierarchically-structured rules, a scheme that offers a high degree of transparency. The system design provides a high degree of flexibility, and allows user-induced customisation. It can be used either as stand-alone or as a component of an integral software system, as it is a Fire and Forest Management Decision Support System, by the use of an appropriate interface.},
  timestamp = {2016-01-20T23:46:31Z},
  number = {1},
  journaltitle = {Ecological Modelling},
  shortjournal = {Ecological Modelling},
  author = {Kaloudis, Spiros and Tocatlidou, Athena and Lorentzos, Nikos A. and Sideridis, Alexander B. and Karteris, Michael},
  urldate = {2016-01-20},
  date = {2005-01-10},
  pages = {25--38},
  keywords = {Decision support system,Fuzzy Sets,Uncertainty Management,Wildfire management,Wildfire risk},
  file = {ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/9B7CBCKU/S0304380004003564.html:;ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/V66P89HP/Kaloudis et al. - 2005 - Assessing Wildfire Destruction Danger a Decision .pdf:application/pdf}
}

@article{spragueframework1980,
  title = {A {{Framework}} for the {{Development}} of {{Decision Support Systems}}},
  volume = {4},
  issn = {0276-7783},
  doi = {10.2307/248957},
  abstract = {This article proposes a framework to explore the nature, scope, and content of the evolving topic of Decision Support Systems (DSS). The first part of the framework considers (a) three levels of technology which have been designated DSS, (b) the developmental approach that is evolving for the creation of a DSS, and (c) the roles of several key types of people in the building and use of a DSS. The second part develops a descriptive model to assess the performance objectives and the capabilities of a DSS as viewed by three of the major participants in their continued development and use. The final section outlines several issues in the future growth and development of a DSS as a potentially valuable type of information system in organizations.},
  timestamp = {2016-01-20T23:45:16Z},
  eprinttype = {jstor},
  eprint = {248957},
  number = {4},
  journaltitle = {MIS Quarterly},
  shortjournal = {MIS Quarterly},
  author = {Sprague, Ralph H.},
  date = {1980},
  pages = {1--26},
  file = {JSTOR Full Text PDF:/Users/ben/Documents/zotero/storage/IZ9QWQH7/Sprague - 1980 - A Framework for the Development of Decision Suppor.pdf:application/pdf}
}

@article{maceachrenvisual2015,
  title = {Visual {{Analytics}} and {{Uncertainty}}: {{Its Not About}} the {{Data}}},
  timestamp = {2016-01-19T22:40:27Z},
  author = {MacEachren, Alan M.},
  date = {2015},
  file = {MacEachren_EUROVA_final_20150402.pdf:/Users/ben/Documents/zotero/storage/IVCND3FM/MacEachren_EUROVA_final_20150402.pdf:application/pdf}
}

@article{zackrole2007,
  title = {The role of decision support systems in an indeterminate world},
  volume = {43},
  issn = {0167-9236},
  url = {http://www.sciencedirect.com/science/article/pii/S0167923606001308},
  doi = {10.1016/j.dss.2006.09.003},
  abstract = {Decision making involves processing or applying information and knowledge, and the appropriate information/knowledge mix depends on the characteristics of the decision making context. Information (or its absence) is central to decision making situations involving uncertainty and complexity, while knowledge (or its absence) is associated with problems of ambiguity and equivocality. This paper proposes that computer-based decision support technologies are appropriate to supporting decision making under conditions of uncertainty and complexity, while human-centric approaches may be more appropriate under conditions of ambiguity or equivocality. Both approaches, however, must be tightly integrated for organizational learning to occur. The framework is illustrated with a case study of the implementation of a decision support system used for price quoting in a leasing company.},
  timestamp = {2016-01-19T22:21:02Z},
  number = {4},
  journaltitle = {Decision Support Systems},
  shortjournal = {Decision Support Systems},
  series = {Special Issue Clusters},
  author = {Zack, Michael H.},
  urldate = {2016-01-19},
  date = {2007-08},
  pages = {1664--1674},
  keywords = {Ambiguity,Complexity,Decision Support Systems,Equivocality,knowledge management,Task technology fit,Uncertainty},
  file = {ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/8BGQTH74/Zack - 2007 - The role of decision support systems in an indeter.pdf:application/pdf;ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/XJDAT8S7/S0167923606001308.html:}
}

@article{tomaszewskigeovisual2012-1,
  title = {Geovisual analytics to support crisis management: {{Information}} foraging for geo-historical context},
  volume = {11},
  issn = {1473-8716, 1473-8724},
  url = {http://ivi.sagepub.com.virtual.anu.edu.au/content/11/4/339},
  doi = {10.1177/1473871612456122},
  shorttitle = {Geovisual analytics to support crisis management},
  abstract = {Information foraging and sense-making with heterogeneous information are context-dependent activities. Thus visual analytics tools to support these activities must incorporate context. But, context is a difficult concept to define, model, and represent. Creating and representing context in support of visually-enabled reasoning about complex problems with complex information is a complementary but different challenge than that addressed in context-aware computing. In the latter, the goal is automated system adaptation to meet user application needs such as location-based services where information about the location, the user, and user goals filters what gets presented on a small mobile device. In contrast, for visual analytics-enabled information foraging and sense-making, the user generally takes an active role in foraging for the contextual information needed to support sense-making in relation to some multifaceted problem. In this paper, we address the challenges of constructing and representing context within visual interfaces that support analytic reasoning in crisis management and humanitarian relief. The challenges stem from the diverse forms of information that can provide context and difficulty in defining and operationalizing context itself. Here, we focus on document foraging to support construction of geographic and historical context for facilitating monitoring and sense-making. Specifically, we present the concept of geo-historical context and outline an empirical assessment of both the concept and its implementation in the Context Discovery Application (CDA), a web-based tool that supports document foraging and sense-making. We also discuss the CDA’s transition into applied use for the United Nations to demonstrate the generality of underlying CDA concepts.},
  timestamp = {2016-01-19T22:06:14Z},
  langid = {english},
  number = {4},
  journaltitle = {Information Visualization},
  shortjournal = {Information Visualization},
  author = {Tomaszewski, Brian and MacEachren, Alan M.},
  urldate = {2016-01-19},
  date = {2012-10-01},
  pages = {339--359},
  keywords = {Context,foraging,mapping,sense-making,text analysis,user studies},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/G87RHIK3/339.html:;Full Text PDF:/Users/ben/Documents/zotero/storage/XWBNP8RW/Tomaszewski and MacEachren - 2012 - Geovisual analytics to support crisis management .pdf:application/pdf}
}

@incollection{thompsondecision2015,
  title = {Decision making under uncertainty: {{Recommendations}} for the {{Wildland Fire Decision Support System}} ({{WFDSS}})},
  url = {http://www.treesearch.fs.fed.us/pubs/49488},
  shorttitle = {Decision making under uncertainty},
  abstract = {The management of wildfire is a dynamic, complex, and fundamentally uncertain enterprise. Fire managers face uncertainties regarding fire weather and subsequent influence on fire behavior, the effects of fire on socioeconomic and ecological resources, and the efficacy of alternative suppression actions on fire outcomes. In these types of difficult decision environments, even well-trained and experienced individuals can become susceptible to cognitive limitations and decision biases, as indicated by several recent analyses of fire manager decision making. This extended abstract focuses on fire management decision making under uncertainty, in relation to current decision support provided by the Wildland Fire Decision Support System (WFDSS), offering several recommendations to improve decision content and process.},
  timestamp = {2016-01-19T06:50:22Z},
  author = {Thompson, Matthew P. ;},
  urldate = {2016-01-19},
  date = {2015},
  pages = {19--23},
  keywords = {fire behavior,fire ecology,fire management,smoke management,social and political consequences},
  file = {Full Text PDF:/Users/ben/Documents/zotero/storage/HDKGFBW3/Thompson - 2015 - Decision making under uncertainty Recommendations.pdf:application/pdf}
}

@article{millerreview2013-1,
  title = {A review of recent advances in risk analysis for wildfire management},
  volume = {22},
  url = {http://dx.doi.org/10.1071/WF11114},
  abstract = {Risk analysis evolved out of the need to make decisions concerning highly stochastic events, and is well suited to analyse the timing, location and potential effects of wildfires. Over the past 10 years, the application of risk analysis to wildland fire management has seen steady growth with new risk-based analytical tools that support a wide range of fire and fuels management planning scales from individual incidents to national, strategic interagency programs. After a brief review of the three components of fire risk -- likelihood, intensity and effects -- this paper reviews recent advances in quantifying and integrating these individual components of fire risk. We also review recent advances in addressing temporal dynamics of fire risk and spatial optimisation of fuels management activities. Risk analysis approaches have become increasingly quantitative and sophisticated but remain quite disparate. We suggest several necessary and fruitful directions for future research and development in wildfire risk analysis.},
  timestamp = {2016-01-19T06:49:41Z},
  number = {1},
  journaltitle = {International Journal of Wildland Fire},
  shortjournal = {Int. J. Wildland Fire},
  author = {Miller, Carol and Ager, Alan A.},
  urldate = {2016-01-19},
  date = {2013},
  pages = {1--14},
  keywords = {burn probability,fire likelihood,hazard,risk assessment,risk science.},
  file = {CSIRO Publishing PDF:/Users/ben/Documents/zotero/storage/QN9MFVZ6/Miller and Ager - 2013 - A review of recent advances in risk analysis for w.pdf:application/pdf}
}

@article{bonazountasdecision2007,
  title = {A decision support system for managing forest fire casualties},
  volume = {84},
  issn = {0301-4797},
  url = {http://www.sciencedirect.com/science/article/pii/S0301479706001769},
  doi = {10.1016/j.jenvman.2006.06.016},
  abstract = {Southern Europe is exposed to anthropogenic and natural forest fires. These result in loss of lives, goods and infrastructure, but also deteriorate the natural environment and degrade ecosystems. The early detection and combating of such catastrophes requires the use of a decision support system (DSS) for emergency management. The current literature reports on a series of efforts aimed to deliver DSSs for the management of the forest fires by utilising technologies like remote sensing and geographical information systems (GIS), yet no integrated system exists.

This manuscript presents the results of scientific research aiming to the development of a DSS for managing forest fires. The system provides a series of software tools for the assessment of the propagation and combating of forest fires based on Arc/Info, ArcView, Arc Spatial Analyst, Arc Avenue, and Visual C++ technologies. The system integrates GIS technologies under the same data environment and utilises a common user interface to produce an integrated computer system based on semi-automatic satellite image processing (fuel maps), socio-economic risk modelling and probabilistic models that would serve as a useful tool for forest fire prevention, planning and management. Its performance has been demonstrated via real time up-to-date accurate information on the position and evolution of the fire. The system can assist emergency assessment, management and combating of the incident. A site demonstration and validation has been accomplished for the island of Evoia, Greece, an area particularly vulnerable to forest fires due to its ecological characteristics and prevailing wind patterns.},
  timestamp = {2016-01-19T06:48:20Z},
  number = {4},
  journaltitle = {Journal of Environmental Management},
  shortjournal = {Journal of Environmental Management},
  author = {Bonazountas, Marc and Kallidromitou, Despina and Kassomenos, Pavlos and Passas, Nikos},
  urldate = {2016-01-19},
  date = {2007-09},
  pages = {412--418},
  keywords = {Decision support system,Forest fire,GIS,Southern Europe},
  file = {ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/7MI66EET/S0301479706001769.html:;ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/CPZ83JPE/Bonazountas et al. - 2007 - A decision support system for managing forest fire.pdf:application/pdf}
}

@article{yuSupport2006,
  title = {Support vector regression for real-time flood stage forecasting},
  volume = {328},
  issn = {0022-1694},
  url = {http://www.sciencedirect.com/science/article/pii/S0022169406000473},
  doi = {10.1016/j.jhydrol.2006.01.021},
  abstract = {Summary
Flood forecasting is an important non-structural approach for flood mitigation. The flood stage is chosen as the variable to be forecasted because it is practically useful in flood forecasting. The support vector machine, a novel artificial intelligence-based method developed from statistical learning theory, is adopted herein to establish a real-time stage forecasting model. The lags associated with the input variables are determined by applying the hydrological concept of the time of response, and a two-step grid search method is applied to find the optimal parameters, and thus overcome the difficulties in constructing the learning machine. Two structures of models used to perform multiple-hour-ahead stage forecasts are developed. Validation results from flood events in Lan-Yang River, Taiwan, revealed that the proposed models can effectively predict the flood stage forecasts one-to-six-hours ahead. Moreover, a sensitivity analysis was conducted on the lags associated with the input variables.},
  timestamp = {2016-01-19T06:42:18Z},
  number = {3--4},
  journaltitle = {Journal of Hydrology},
  journal = {Journal of Hydrology},
  year={2016},
  shortjournal = {Journal of Hydrology},
  series = {The ICWRER - Symposium in Dresden, Germany},
  author = {Yu, Pao-Shan and Chen, Shien-Tsung and Chang, I-Fan},
  urldate = {2016-01-19},
  date = {2006-09-15},
  pages = {704--716},
  keywords = {Flood forecasting,Parameter optimization,Support vector regression,Water stage},
  file = {ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/MQP4CFSQ/Yu et al. - 2006 - Support vector regression for real-time flood stag.pdf:application/pdf;ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/PNI35VT6/S0022169406000473.html:}
}

@article{levymultiple2005,
  title = {Multiple criteria decision making and decision support systems for flood risk management},
  volume = {19},
  issn = {1436-3240, 1436-3259},
  url = {http://link.springer.com/article/10.1007/s00477-005-0009-2},
  doi = {10.1007/s00477-005-0009-2},
  abstract = {Multiple criteria decision making (MCDM) is a collection of methodologies to compare, select, or rank multiple alternatives that typically involve incommensurate attributes. MCDM is well-suited for eliciting and modeling the flood preferences of stakeholders and for improving the coordination among flood agencies, organizations and affected citizens. A flood decision support system (DSS) architecture is put forth that integrates the latest advances in MCDM, remote sensing, GIS, hydrologic models, and real-time flood information systems. The analytic network process (ANP) is discussed with application to short-term flood management options for the middle reaches of the Yangtze River. It is shown that DSS and MCDM can improve flood risk planning and management under uncertainty by providing data displays, analytical results, and model output to summarize critical flood information.},
  timestamp = {2016-01-19T06:41:43Z},
  langid = {english},
  number = {6},
  journaltitle = {Stochastic Environmental Research and Risk Assessment},
  shortjournal = {Stoch Environ Res Ris Assess},
  author = {Levy, Jason K.},
  urldate = {2016-01-19},
  date = {2005-10-08},
  pages = {438--447},
  keywords = {Decision Support Systems,Flooding,Math. Applications in Geosciences,Math. Appl. in Environmental Science,Numerical and Computational Methods in Engineering,Probability Theory and Stochastic Processes,risk management,Statistics for Engineering; Physics; Computer Science; Chemistry & Geosciences,Waste Water Technology / Water Pollution Control / Water Management / Aquatic Pollution},
  file = {Full Text PDF:/Users/ben/Documents/zotero/storage/JVRISUF9/Levy - 2005 - Multiple criteria decision making and decision sup.pdf:application/pdf;Snapshot:/Users/ben/Documents/zotero/storage/Z4HBNJJS/s00477-005-0009-2.html:}
}

@article{rouxthreat2007,
  title = {Threat evaluation and weapon assignment decision support: {{A}} review of the state of the art},
  volume = {23},
  rights = {Copyright is held by Operations Research Society of South Africa},
  issn = {0529-191-X},
  url = {http://www.ajol.info/index.php/orion/article/view/34267},
  shorttitle = {Threat evaluation and weapon assignment decision support},
  timestamp = {2016-01-19T06:31:09Z},
  langid = {english},
  number = {2},
  journaltitle = {ORiON},
  shortjournal = {ORiON},
  author = {Roux, J. N. and Vuuren, J. H. Van},
  urldate = {2016-01-19},
  date = {2007},
  pages = {151--187},
  keywords = {decision support.,Threat evaluation,weapon assignment},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/PS5TRV56/34267.html:;Full Text PDF:/Users/ben/Documents/zotero/storage/XQ42HAKG/Roux and Vuuren - 2007 - Threat evaluation and weapon assignment decision s.pdf:application/pdf}
}

@article{kinkeldeyhow2014,
  title = {How to {{Assess Visual Communication}} of {{Uncertainty}}? {{A Systematic Review}} of {{Geospatial Uncertainty Visualisation User Studies}}},
  volume = {51},
  issn = {0008-7041},
  url = {http://www.maneyonline.com/doi/abs/10.1179/1743277414Y.0000000099},
  doi = {10.1179/1743277414Y.0000000099},
  shorttitle = {How to {{Assess Visual Communication}} of {{Uncertainty}}?},
  abstract = {For decades, uncertainty visualisation has attracted attention in disciplines such as cartography and geographic visualisation, scientific visualisation and information visualisation. Most of this research deals with the development of new approaches to depict uncertainty visually; only a small part is concerned with empirical evaluation of such techniques. This systematic review aims to summarize past user studies and describe their characteristics and findings, focusing on the field of geographic visualisation and cartography and thus on displays containing geospatial uncertainty. From a discussion of the main findings, we derive lessons learned and recommendations for future evaluation in the field of uncertainty visualisation. We highlight the importance of user tasks for successful solutions and recommend moving towards task-centered typologies to support systematic evaluation in the field of uncertainty visualisation.},
  timestamp = {2016-01-19T04:13:39Z},
  number = {4},
  journaltitle = {The Cartographic Journal},
  shortjournal = {Cartogr. J.},
  author = {Kinkeldey, Christoph and MacEachren, Alan M. and Schiewe, Jochen},
  urldate = {2016-01-19},
  date = {2014-09-01},
  pages = {372--386},
  file = {Full Text PDF:/Users/ben/Documents/zotero/storage/B37HFKDZ/Kinkeldey et al. - 2014 - How to Assess Visual Communication of Uncertainty.pdf:application/pdf;Snapshot:/Users/ben/Documents/zotero/storage/MP6AU3R9/1743277414Y.html:}
}

@incollection{harrisonincorporating2014,
  title = {Incorporating {{Uncertainty}} in {{Intrusion Detection}} to {{Enhance Decision Making}}},
  rights = {©2014 Springer-Verlag London},
  isbn = {978-1-4471-6496-8 978-1-4471-6497-5},
  url = {http://link.springer.com/chapter/10.1007/978-1-4471-6497-5_7},
  abstract = {Network security defense often involves uncertain data which can lead to uncertain judgments regarding the existence and extent of attacks. However, analytic uncertainty and false positive decisions can be integrated into analysis tools to facilitate the process of decision making. This paper presents an interactive method to specify and visualize uncertain decisions to assist in the detection process of network intrusions. Uncertain decisions on the degree of suspicious activity for both temporal durations and individual nodes are integrated into the analysis process to aide in revealing hidden attack patterns. Our approach has been implemented in an existing security visualization system, which is used as the baseline for comparing the effects of newly added uncertainty visualization component. The case studies and comparison results demonstrate that uncertainty visualization can significantly improve the decision making process for attack detection.},
  timestamp = {2016-01-19T04:12:44Z},
  langid = {english},
  booktitle = {Scientific {{Visualization}}},
  series = {Mathematics and Visualization},
  publisher = {{Springer London}},
  author = {Harrison, Lane and Lu, Aidong},
  editor = {Hansen, Charles D. and Chen, Min and Johnson, Christopher R. and Kaufman, Arie E. and Hagen, Hans},
  urldate = {2016-01-19},
  date = {2014},
  pages = {71--78},
  keywords = {Computer Graphics,Computer Imaging; Vision; Pattern Recognition and Graphics,Visualization},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/9VZ8C3Z2/978-1-4471-6497-57.html:},
  doi = {10.1007/978-1-4471-6497-57}
}

@article{deitrickdeveloping2015,
  title = {Developing {{Implicit Uncertainty Visualization Methods Motivated}} by {{Theories}} in {{Decision Science}}},
  volume = {105},
  issn = {0004-5608},
  url = {http://dx.doi.org/10.1080/00045608.2015.1012635},
  doi = {10.1080/00045608.2015.1012635},
  abstract = {Agreement between public policy decision makers and geographic information systems and visualization researchers about the importance of uncertainty in decision support sits in contrast to a disconnect in approaches to incorporating uncertainty into decision support tools. This disconnect does not arise from how these two groups define uncertainty but instead occurs because they approach uncertainty from different problem perspectives (Miller et al. 2008; Pohl 2011). Public policy decision makers regularly contend with uncertainty based on how proposed policies will affect the future, resulting in a solutions-oriented approach that relates uncertainty of future conditions to policy outcomes. For researchers, uncertainty more often reflects unknowns in data values or modeling processes, such as the difference between a measured or predicted value and the actual value, resulting in a knowledge-production approach that relates uncertainty to the validity and legitimacy of methods, models, and data to produce knowledge. The research presented here contends that this gap between research and practice (Brown and Vari 1992; von Winterfeldt 2013) stems from these differing perspectives. To bridge this gap, we examine decision science theories to explain decision makers’ solutions-oriented approach to uncertainty. Decision science is concerned with understanding and improving how individuals or groups identify problems, make decisions, and learn from the outcomes. We then present a new methodology, implicit uncertainty visualization, that reflects how decision makers contend with uncertainty. Bridging this gap opens up opportunities to develop visualization methods and tools that help decision makers better deal with uncertainty in practice.},
  timestamp = {2016-01-19T04:11:49Z},
  number = {3},
  journaltitle = {Annals of the Association of American Geographers},
  shortjournal = {Ann. Assoc. Am. Geogr.},
  author = {Deitrick, Stephanie and Wentz, Elizabeth A.},
  urldate = {2016-01-19},
  date = {2015-05-04},
  pages = {531--551},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/FTZ3GG22/00045608.2015.html:;Full Text PDF:/Users/ben/Documents/zotero/storage/H2QWXCGX/Deitrick and Wentz - 2015 - Developing Implicit Uncertainty Visualization Meth.pdf:application/pdf}
}

@article{riveiroeffects2014,
  title = {Effects of visualizing uncertainty on decision-making in a target identification scenario},
  volume = {41},
  issn = {0097-8493},
  url = {http://www.sciencedirect.com/science/article/pii/S0097849314000302},
  doi = {10.1016/j.cag.2014.02.006},
  abstract = {This paper presents an empirical study that addresses the effects the visualization of uncertainty has on decision-making. We focus our investigations on an area where uncertainty plays an important role and the decision time is limited. For that, we selected an air defense scenario, where expert operators have a few minutes to make a well-informed decision based on uncertain sensor data regarding the identity of an object and where the consequences of a late or wrong decision are severe.

An approach for uncertainty visualization is proposed and tested using a prototype that supports the interactive analysis of multivariate spatio-temporal sensor data. The uncertainty visualization embeds the accuracy of the sensor data values using the thickness of the lines in the graphical representation of the sensor values. Semi-transparent filled circles represent the uncertain position, while a track quality value between 0 and 1 accounts for the quality of the estimated track for each target. Twenty-two experienced air traffic operators were divided into two groups (with and without uncertainty visualization) and carried out identification and prioritization tasks using the prototype. The results show that the group aided by visualizations of uncertainty needed significantly fewer attempts to make a final identification, and a significant difference between the groups when considering the identities and priorities assigned was observed (participants with uncertainty visualization selected higher priority values and more hostile and suspect identities). These results may show that experts put themselves in the “worst-case scenario” in the presence of uncertainty when safety is an issue. Additionally, the presentation of uncertainty neither increased the participants׳ expressed workload, nor the time needed to make a classification. However, the inclusion of the uncertainty information did not have a significant effect on the performance (true positives, false negatives and false positives) or the participants׳ expressed confidence in their decisions.},
  timestamp = {2016-01-19T04:11:07Z},
  journaltitle = {Computers \& Graphics},
  shortjournal = {Computers \& Graphics},
  author = {Riveiro, Maria and Helldin, Tove and Falkman, Göran and Lebram, Mikael},
  urldate = {2016-01-19},
  date = {2014-06},
  pages = {84--98},
  keywords = {Confidence,Decision-making,performance,Target identification,Uncertainty visualization,Workload},
  file = {ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/KTN4ICCC/Riveiro et al. - 2014 - Effects of visualizing uncertainty on decision-mak.pdf:application/pdf;ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/XXT3HXIF/S0097849314000302.html:}
}

@incollection{bonneauoverview2014,
  title = {Overview and {{State}}-of-the-{{Art}} of {{Uncertainty Visualization}}},
  rights = {©2014 Springer-Verlag London},
  isbn = {978-1-4471-6496-8 978-1-4471-6497-5},
  url = {http://link.springer.com/chapter/10.1007/978-1-4471-6497-5_1},
  abstract = {The goal of visualization is to effectively and accurately communicate data. Visualization research has often overlooked the errors and uncertainty which accompany the scientific process and describe key characteristics used to fully understand the data. The lack of these representations can be attributed, in part, to the inherent difficulty in defining, characterizing, and controlling this uncertainty, and in part, to the difficulty in including additional visual metaphors in a well designed, potent display. However, the exclusion of this information cripples the use of visualization as a decision making tool due to the fact that the display is no longer a true representation of the data. This systematic omission of uncertainty commands fundamental research within the visualization community to address, integrate, and expect uncertainty information. In this chapter, we outline sources and models of uncertainty, give an overview of the state-of-the-art, provide general guidelines, outline small exemplary applications, and finally, discuss open problems in uncertainty visualization.},
  timestamp = {2016-01-19T04:09:58Z},
  langid = {english},
  booktitle = {Scientific {{Visualization}}},
  series = {Mathematics and Visualization},
  publisher = {{Springer London}},
  author = {Bonneau, Georges-Pierre and Hege, Hans-Christian and Johnson, Chris R. and Oliveira, Manuel M. and Potter, Kristin and Rheingans, Penny and Schultz, Thomas},
  editor = {Hansen, Charles D. and Chen, Min and Johnson, Christopher R. and Kaufman, Arie E. and Hagen, Hans},
  urldate = {2016-01-19},
  date = {2014},
  pages = {3--27},
  keywords = {Computer Graphics,Computer Imaging; Vision; Pattern Recognition and Graphics,Visualization},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/6M9ZZ4PS/978-1-4471-6497-5_1.html:;Overview-Uncertainty-Visualization-2015.pdf:/Users/ben/Documents/zotero/storage/PZPXD873/Overview-Uncertainty-Visualization-2015.pdf:application/pdf},
  doi = {10.1007/978-1-4471-6497-5_1}
}

@incollection{deitrickmaking2008,
  title = {Making {{Uncertainty Usable}}: {{Approaches}} for {{Visualizing Uncertainty Information}}},
  rights = {Copyright \%C2\%A9 2008 John Wiley \& Sons, Ltd},
  isbn = {978-0-470-98764-3},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/9780470987643.ch14/summary},
  shorttitle = {Making {{Uncertainty Usable}}},
  abstract = {This chapter contains sections titled:

* Introduction: the need for representations of uncertainty
* The complexity of uncertainty
* Uncertainty visualization: a user-centred research agenda
* Conclusion
* References},
  timestamp = {2016-01-19T04:09:31Z},
  langid = {english},
  booktitle = {Geographic {{Visualization}}},
  publisher = {{John Wiley \& Sons, Ltd}},
  author = {Deitrick, Stephanie and Edsall, Robert},
  editor = {Lecturer, rtin Dodge and Officer, ry McDerby Visualization Support and Leader, rtin Turner Visualization Team},
  urldate = {2016-01-19},
  date = {2008},
  pages = {277--291},
  keywords = {cartography; visualization and GIScience research,communicating uncertainty and spatial data quality,complexity of uncertainty,decision problem presentation and decision frame,GIScience uncertainty visualization,risk management; uncertainty; and communication,uncertainty communication methods,uncertainty study and pervasiveness of uncertainty},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/SEDZ6W4N/summary.html:}
}

@inproceedings{boukhelifauncertainty2009,
  location = {{New York, NY, USA}},
  title = {Uncertainty {{Visualization}}: {{Why Might It Fail}}?},
  isbn = {978-1-60558-247-4},
  url = {http://doi.acm.org/10.1145/1520340.1520616},
  doi = {10.1145/1520340.1520616},
  shorttitle = {Uncertainty {{Visualization}}},
  abstract = {There is a gulf between the rhetoric in visualization about the importance of uncertainty, and the practice of visualization in which uncertainty is rarely seen other than as a laboratory exercise. We reflect on why something viewed as fundamental in science and engineering is rarely if ever adopted in visualization practice. Our analysis is informed both by research progress and by our own experience in an ongoing industrial case study on modelling and mapping underground assets, where it would appear that uncertainty plays a major role. In this case study, we try to identify promoting and limiting factors. We conclude that the value of uncertainty visualization is severely limited by the quality and scope of uncertainty data, by the limited confidence in the data itself, and by the perceptual and cognitive confusion that the depiction of this data can generate. We hope to broaden the discussion on the utility of uncertainty in visualization from the purely technical and perceptual issues to social and organizational factors.},
  timestamp = {2016-01-19T04:09:01Z},
  booktitle = {{{CHI}} '09 {{Extended Abstracts}} on {{Human Factors}} in {{Computing Systems}}},
  series = {CHI EA '09},
  publisher = {{ACM}},
  author = {Boukhelifa, Nadia and Duke, David John},
  urldate = {2016-01-19},
  date = {2009},
  pages = {4051--4056},
  keywords = {maps,plans,Uncertainty,Visualization},
  file = {ACM Full Text PDF:/Users/ben/Documents/zotero/storage/CBH89NMF/Boukhelifa and Duke - 2009 - Uncertainty Visualization Why Might It Fail.pdf:application/pdf}
}

@article{wuvisualizing2012,
  title = {Visualizing {{Flow}} of {{Uncertainty}} through {{Analytical Processes}}},
  volume = {18},
  issn = {1077-2626},
  doi = {10.1109/TVCG.2012.285},
  abstract = {Uncertainty can arise in any stage of a visual analytics process, especially in data-intensive applications with a sequence of data transformations. Additionally, throughout the process of multidimensional, multivariate data analysis, uncertainty due to data transformation and integration may split, merge, increase, or decrease. This dynamic characteristic along with other features of uncertainty pose a great challenge to effective uncertainty-aware visualization. This paper presents a new framework for modeling uncertainty and characterizing the evolution of the uncertainty information through analytical processes. Based on the framework, we have designed a visual metaphor called uncertainty flow to visually and intuitively summarize how uncertainty information propagates over the whole analysis pipeline. Our system allows analysts to interact with and analyze the uncertainty information at different levels of detail. Three experiments were conducted to demonstrate the effectiveness and intuitiveness of our design.},
  timestamp = {2016-01-19T04:08:19Z},
  number = {12},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  shortjournal = {IEEE Trans. Vis. Comput. Graph.},
  author = {Wu, Yingcai and Yuan, Guo-Xun and Ma, Kwan-Liu},
  date = {2012-12},
  pages = {2526--2535},
  keywords = {analysis pipeline,analytical processes,Covariance matrix,data analysis,data-intensive applications,data transformation,data transformations,data visualisation,Data visualization,Ellipsoids,error ellipsoids,multivariate data analysis,Uncertainty,uncertainty-aware visualization,uncertainty flow visualization,uncertainty fusion,uncertainty propagation,Uncertainty quantification,Uncertainty visualization,Visual analytics,visual analytics process,visual metaphor},
  file = {IEEE Xplore Abstract Record:/Users/ben/Documents/zotero/storage/EMRATMI3/absall.html:;IEEE Xplore Full Text PDF:/Users/ben/Documents/zotero/storage/TG6E8IHX/Wu et al. - 2012 - Visualizing Flow of Uncertainty through Analytical.pdf:application/pdf}
}

@article{viardadjacent2011,
  title = {Adjacent versus coincident representations of geospatial uncertainty: {{Which}} promote better decisions?},
  volume = {37},
  issn = {0098-3004},
  url = {http://www.sciencedirect.com/science/article/pii/S0098300410003067},
  doi = {10.1016/j.cageo.2010.08.004},
  shorttitle = {Adjacent versus coincident representations of geospatial uncertainty},
  abstract = {3D geological models commonly built to manage natural resources are much affected by uncertainty because most of the subsurface is inaccessible to direct observation. Appropriate ways to intuitively visualize uncertainties are therefore critical to draw appropriate decisions. However, empirical assessments of uncertainty visualization for decision making are currently limited to 2D map data, while most geological entities are either surfaces embedded in a 3D space or volumes.

This paper first reviews a typical example of decision making under uncertainty, where uncertainty visualization methods can actually make a difference. This issue is illustrated on a real Middle East oil and gas reservoir, looking for the optimal location of a new appraisal well. In a second step, we propose a user study that goes beyond traditional 2D map data, using 2.5D pressure data for the purposes of well design. Our experiments study the quality of adjacent versus coincident representations of spatial uncertainty as compared to the presentation of data without uncertainty; the representations' quality is assessed in terms of decision accuracy. Our study was conducted within a group of 123 graduate students specialized in geology.},
  timestamp = {2016-01-19T04:07:29Z},
  number = {4},
  journaltitle = {Computers \& Geosciences},
  shortjournal = {Computers \& Geosciences},
  author = {Viard, Thomas and Caumon, Guillaume and Lévy, Bruno},
  urldate = {2016-01-19},
  date = {2011-04},
  pages = {511--520},
  keywords = {Perception,Transparency,Uncertainty visualization,User study},
  file = {ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/KBE2XZEA/Viard et al. - 2011 - Adjacent versus coincident representations of geos.pdf:application/pdf;ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/QNZKZHCZ/S0098300410003067.html:}
}

@book{deitrickinfluence2006,
  title = {The influence of uncertainty visualization on decision making: {{An}} empirical evaluation},
  isbn = {3-540-35588-X},
  timestamp = {2016-01-19T04:06:29Z},
  publisher = {{Springer}},
  author = {Deitrick, Stephanie and Edsall, Robert},
  date = {2006},
  file = {Microsoft Word - Uncertainty Visualization And Decision Making.doc.pdf:/Users/ben/Documents/zotero/storage/J6SCFSPM/Microsoft Word - Uncertainty Visualization And Decision Making.doc.pdf:application/pdf}
}

@article{schulzdesign2013,
  title = {A {{Design Space}} of {{Visualization Tasks}}},
  volume = {19},
  issn = {1077-2626},
  doi = {10.1109/TVCG.2013.120},
  abstract = {Knowledge about visualization tasks plays an important role in choosing or building suitable visual representations to pursue them. Yet, tasks are a multi-faceted concept and it is thus not surprising that the many existing task taxonomies and models all describe different aspects of tasks, depending on what these task descriptions aim to capture. This results in a clear need to bring these different aspects together under the common hood of a general design space of visualization tasks, which we propose in this paper. Our design space consists of five design dimensions that characterize the main aspects of tasks and that have so far been distributed across different task descriptions. We exemplify its concrete use by applying our design space in the domain of climate impact research. To this end, we propose interfaces to our design space for different user roles (developers, authors, and end users) that allow users of different levels of expertise to work with it.},
  timestamp = {2016-01-19T03:40:18Z},
  number = {12},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  shortjournal = {IEEE Trans. Vis. Comput. Graph.},
  author = {Schulz, H.-J. and Nocke, T. and Heitzler, M. and Schumann, H.},
  date = {2013-12},
  pages = {2366--2375},
  keywords = {Algorithms,Climate,climate impact research,Computer Graphics,Computer simulation,data visualisation,Data visualization,design space,Market research,Meteorology,Models; Theoretical,Software,Software design,Task taxonomy,taxonomy,User-Computer Interface,visualization recommendation,visualization task descriptions,visualization task model,visualization tasks design space,visualization task taxonomy,visual representations},
  file = {IEEE Xplore Full Text PDF:/Users/ben/Documents/zotero/storage/76T3B8GG/Schulz et al. - 2013 - A Design Space of Visualization Tasks.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/ben/Documents/zotero/storage/8ADM7UCS/absall.html:}
}

@article{greenskull1996,
  title = {The skull beneath the skin: entity-relationship models of information artifacts},
  volume = {44},
  issn = {1071-5819},
  url = {http://www.sciencedirect.com/science/article/pii/S1071581996900348},
  doi = {10.1006/ijhc.1996.0034},
  shorttitle = {The skull beneath the skin},
  abstract = {Data modelling reveals the internal structure of an information system, abstracting away from details of the physical representation. We show that entity-relationship modelling, a well-tried example of a data-modelling technique, can be applied to both interactive and noninteractive information artifacts in the domain of HCI. By extending the conventional ER notation slightly (to give ERMIA, Entity-Relationship Modelling for Information Artifacts) it can be used to describe differences between different representations of the same information, differences between user's conceptual models of the same device, and the structure and update requirements of distributed information in a worksystem. It also yields symbolic-level estimates of Card, Pirolli and Mackinlay's index of “cost-of-knowledge” in an information structure, plus a novel index, the “cost-of-update”; these symbolic estimates offer a useful complement to the highly detailed analyses of time costs obtainable from GOMS-like models. We conclude that, as a cheap, coarse-grained, and easy-to-learn modelling technique, ERMIA usefully fills a gap in the range of available HCI analysis techniques.},
  timestamp = {2016-01-19T03:39:49Z},
  number = {6},
  journaltitle = {International Journal of Human-Computer Studies},
  shortjournal = {International Journal of Human-Computer Studies},
  author = {Green, T. R. G. and Benyon, D. R.},
  urldate = {2016-01-19},
  date = {1996-06},
  pages = {801--828},
  file = {ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/43C2AG7I/S1071581996900348.html:;ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/NDIGB4A3/Green and Benyon - 1996 - The skull beneath the skin entity-relationship mo.pdf:application/pdf}
}

@inproceedings{tweediecharacterizing1997,
  location = {{New York, NY, USA}},
  title = {Characterizing {{Interactive Externalizations}}},
  isbn = {978-0-89791-802-2},
  url = {http://doi.acm.org/10.1145/258549.258803},
  doi = {10.1145/258549.258803},
  timestamp = {2016-01-19T03:39:13Z},
  booktitle = {Proceedings of the {{ACM SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  series = {CHI '97},
  publisher = {{ACM}},
  author = {Tweedie, Lisa},
  urldate = {2016-01-19},
  date = {1997},
  pages = {375--382},
  keywords = {interactive graphics,taxonomy,Visualization},
  file = {ACM Full Text PDF:/Users/ben/Documents/zotero/storage/F2Z9AMF6/Tweedie - 1997 - Characterizing Interactive Externalizations.pdf:application/pdf}
}

@article{sharpleswindterrain2012,
  title = {Wind--terrain effects on the propagation of wildfires in rugged terrain: fire channelling},
  volume = {21},
  url = {http://dx.doi.org/10.1071/WF10055},
  shorttitle = {Wind--terrain effects on the propagation of wildfires in rugged terrain},
  abstract = {The interaction of wind, terrain and a fire burning in a landscape can produce a variety of unusual yet significant effects on fire propagation. One such example, in which a fire exhibits rapid spread in a direction transverse to the synoptic winds as well as in the usual downwind direction, is considered in this paper. This type of fire spread, which is referred to as ‘fire channelling’, is characterised by intense lateral and downwind spotting and production of extensive flaming zones. The dependence of fire channelling on wind and terrain is analysed using wind, terrain and multispectral fire data collected during the January 2003 Alpine fires over south-eastern Australia. As part of the analysis, a simple terrain-filter model is utilised to confirm a quantitative link between instances of fire channelling and parts of the terrain that are sufficiently steep and lee-facing. By appealing to the theory of wind--terrain interaction and the available evidence, several processes that could produce the atypical fire spread are considered and some discounted. Based on the processes that could not be discounted, and a previous analysis of wind regimes in rugged terrain, a likely explanation for the fire channelling phenomenon is hypothesised. Implications of fire channelling for bushfire risk management are also discussed.},
  timestamp = {2016-01-19T02:59:31Z},
  number = {3},
  journaltitle = {International Journal of Wildland Fire},
  shortjournal = {Int. J. Wildland Fire},
  author = {Sharples, Jason J. and McRae, Richard H. D. and Wilkes, Stephen R.},
  urldate = {2016-01-19},
  date = {2012},
  pages = {282--296},
  file = {CSIRO Publishing PDF:/Users/ben/Documents/zotero/storage/HEC9R99S/Sharples et al. - 2012 - Wind--terrain effects on the propagation of wildfir.pdf:application/pdf}
}

@article{chenuncertaintyaware2015,
  title = {Uncertainty-{{Aware Multidimensional Ensemble Data Visualization}} and {{Exploration}}},
  volume = {21},
  issn = {1077-2626},
  doi = {10.1109/TVCG.2015.2410278},
  abstract = {This paper presents an efficient visualization and exploration approach for modeling and characterizing the relationships and uncertainties in the context of a multidimensional ensemble dataset. Its core is a novel dissimilarity-preserving projection technique that characterizes not only the relationships among the mean values of the ensemble data objects but also the relationships among the distributions of ensemble members. This uncertainty-aware projection scheme leads to an improved understanding of the intrinsic structure in an ensemble dataset. The analysis of the ensemble dataset is further augmented by a suite of visual encoding and exploration tools. Experimental results on both artificial and real-world datasets demonstrate the effectiveness of our approach.},
  timestamp = {2016-01-19T02:55:37Z},
  number = {9},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  shortjournal = {IEEE Trans. Vis. Comput. Graph.},
  author = {Chen, Haidong and Zhang, Song and Chen, Wei and Mei, Honghui and Zhang, Jiawei and Mercer, A. and Liang, Ronghua and Qu, Huamin},
  date = {2015-09},
  pages = {1072--1086},
  keywords = {Bandwidth,data visualisation,Data visualization,dissimilarity-preserving projection technique,—Ensemble visualization,Ensemble visualization,multidimensional data visualization,multidimensional ensemble dataset,Numerical models,Solid modeling,Symmetric matrices,Uncertainty,uncertainty-aware multidimensional ensemble data exploration,uncertainty-aware multidimensional ensemble data visualization,Uncertainty quantification,Uncertainty visualization,visual encoding,visual exploration tools,Visualization},
  file = {IEEE Xplore Abstract Record:/Users/ben/Documents/zotero/storage/FU3KZKNX/abs_all.html:;IEEE Xplore Full Text PDF:/Users/ben/Documents/zotero/storage/K33NQHJ9/Chen et al. - 2015 - Uncertainty-Aware Multidimensional Ensemble Data V.pdf:application/pdf}
}

@article{sanyalnoodles2010,
  title = {Noodles: {{A Tool}} for {{Visualization}} of {{Numerical Weather Model Ensemble Uncertainty}}},
  volume = {16},
  issn = {1077-2626},
  doi = {10.1109/TVCG.2010.181},
  shorttitle = {Noodles},
  abstract = {Numerical weather prediction ensembles are routinely used for operational weather forecasting. The members of these ensembles are individual simulations with either slightly perturbed initial conditions or different model parameterizations, or occasionally both. Multi-member ensemble output is usually large, multivariate, and challenging to interpret interactively. Forecast meteorologists are interested in understanding the uncertainties associated with numerical weather prediction; specifically variability between the ensemble members. Currently, visualization of ensemble members is mostly accomplished through spaghetti plots of a single midtroposphere pressure surface height contour. In order to explore new uncertainty visualization methods, the Weather Research and Forecasting (WRF) model was used to create a 48-hour, 18 member parameterization ensemble of the 13 March 1993 "Superstorm". A tool was designed to interactively explore the ensemble uncertainty of three important weather variables: water-vapor mixing ratio, perturbation potential temperature, and perturbation pressure. Uncertainty was quantified using individual ensemble member standard deviation, inter-quartile range, and the width of the 95\% confidence interval. Bootstrapping was employed to overcome the dependence on normality in the uncertainty metrics. A coordinated view of ribbon and glyph-based uncertainty visualization, spaghetti plots, iso-pressure colormaps, and data transect plots was provided to two meteorologists for expert evaluation. They found it useful in assessing uncertainty in the data, especially in finding outliers in the ensemble run and therefore avoiding the WRF parameterizations that lead to these outliers. Additionally, the meteorologists could identify spatial regions where the uncertainty was significantly high, allowing for identification of poorly simulated storm environments and physical interpretation of these model issues.},
  timestamp = {2016-01-19T02:54:10Z},
  number = {6},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  shortjournal = {IEEE Trans. Vis. Comput. Graph.},
  author = {Sanyal, J. and Zhang, Song and Dyer, J. and Mercer, A. and Amburn, P. and Moorhead, R.J.},
  date = {2010-11},
  pages = {1421--1430},
  keywords = {Atmospheric modeling,bootstrapping,data transect plots,data visualisation,Data visualization,ensemble member standard deviation,geographic/geospatial visualization,geophysics computing,glyph-based techniques,glyph-based uncertainty visualization,interquartile range,isopressure colormaps,midtroposphere pressure surface height contour,Noodles,Numerical models,numerical weather model ensemble uncertainty,numerical weather prediction ensembles,operational weather forecasting,perturbation potential temperature,perturbation pressure,Predictive models,qualitative evaluation,spaghetti plots,timevarying data,Uncertainty,Uncertainty visualization,visualization tool,water-vapor mixing ratio,weather ensemble,weather forecasting},
  file = {IEEE Xplore Full Text PDF:/Users/ben/Documents/zotero/storage/V6KR5NA5/Sanyal et al. - 2010 - Noodles A Tool for Visualization of Numerical Wea.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/ben/Documents/zotero/storage/Z2FSIXIH/absall.html:}
}

@incollection{potterquantification2012,
  title = {From quantification to visualization: {{A}} taxonomy of uncertainty visualization approaches},
  isbn = {3-642-32676-5},
  timestamp = {2016-01-19T02:53:00Z},
  booktitle = {Uncertainty {{Quantification}} in {{Scientific Computing}}},
  publisher = {{Springer}},
  author = {Potter, Kristin and Rosen, Paul and Johnson, Chris R.},
  date = {2012},
  pages = {226--249},
  file = {potter-2012-FQTV.pdf:/Users/ben/Documents/zotero/storage/E4G5ZKG6/potter-2012-FQTV.pdf:application/pdf}
}

@article{beltondecision1994,
  title = {Decision support systems: {{Learning}} from visual interactive modelling},
  volume = {12},
  issn = {0167-9236},
  url = {http://www.sciencedirect.com/science/article/pii/0167923694900523},
  doi = {10.1016/0167-9236(94)90052-3},
  shorttitle = {Decision support systems},
  abstract = {The two research fields of, in the first instance, Decision Support Systems (DSS) and then secondly, Visual Interactive Modelling (VIM) have developed by mostly independent research. Yet these two fields seek many common goals. The VIM field has been seen as a largely technical development aiding certain Operational Research methods. On the other hand DSS have developed in the wider context of a recognition of a need to provide directed and helpful information to support decision making. In this paper we develop, firstly, an understanding of VIM in the context of current thinking on DSS. Ostensibly, it would seem that VIM is simply a DSS with a sophisticated user interface. However, we argue that VIM is an approach which has at its core an ability to allow decision makers to learn about their own subjective values while modelling technical issues. We suggest that embracing this learning objective at the design stage will enhance the power of Visual Interactive Models in particular and Decision Support Systems in general.},
  timestamp = {2016-01-19T02:50:13Z},
  number = {4},
  journaltitle = {Decision Support Systems},
  shortjournal = {Decision Support Systems},
  author = {Belton, Valerie and Elder, Mark D.},
  urldate = {2016-01-19},
  date = {1994-11-01},
  pages = {355--364},
  keywords = {Decision Support Systems,Learning,Visual Interactive Modelling},
  file = {ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/FJHV7CT5/0167923694900523.html:}
}

@article{bellvisual1991,
  title = {Visual interactive modelling: {{The}} past, the present, and the prospects},
  volume = {54},
  issn = {0377-2217},
  url = {http://www.sciencedirect.com/science/article/pii/037722179190101Z},
  doi = {10.1016/0377-2217(91)90101-Z},
  shorttitle = {Visual interactive modelling},
  abstract = {This article presents the conceptual foundations of visual interactive modelling (VIM), and reviews important recent developments in VIM and its application areas. Finally, the prospects for VIM are assessed, together with five areas where there opportunities for operational researchers to continue to play a significant role in the future of VIM.},
  timestamp = {2016-01-19T02:49:42Z},
  number = {3},
  journaltitle = {European Journal of Operational Research},
  shortjournal = {European Journal of Operational Research},
  series = {Visual Interactive Modelling},
  author = {Bell, Peter C.},
  urldate = {2016-01-19},
  date = {1991-10-16},
  pages = {274--286},
  keywords = {methodology,Visual Interactive Modelling},
  file = {ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/KKC9FCFH/Bell - 1991 - Visual interactive modelling The past, the presen.pdf:application/pdf;ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/V9TBUCI2/037722179190101Z.html:}
}

@article{dhirenhancing2001-1,
  title = {Enhancing {{Management}}'s {{Understanding}} of {{Operational Research Models}}},
  volume = {52},
  issn = {0160-5682},
  abstract = {The problem of the gap between management's understanding of a model and the model builder's insight is a large one. This problem continues to challenge the practice of operational research and plague contemporary modelling efforts. This paper offers an approach to enhancing a manager's understanding of the model with respect to an application. It sets out a procedure whereby (a) the reasons for the management's judgements are uncovered, and (b) the sources of disagreement with the recommendations obtained from the model are identified. The manager, learning from the model, may then change his or her judgements. Alternatively, the model builder may modify the model parameters or assumptions, leading to convergent understanding. The procedure is based on the framework of social judgement theory. An illustrative example is offered in the context of facility planning in the cement manufacturing industry.},
  timestamp = {2016-01-19T02:44:48Z},
  eprinttype = {jstor},
  eprint = {822948},
  number = {8},
  journaltitle = {The Journal of the Operational Research Society},
  shortjournal = {The Journal of the Operational Research Society},
  author = {Dhir, K. S.},
  date = {2001},
  pages = {873--887},
  file = {JSTOR Full Text PDF:/Users/ben/Documents/zotero/storage/XWA2HUI2/Dhir - 2001 - Enhancing Management's Understanding of Operationa.pdf:application/pdf}
}

@article{belldecisionmakers1999,
  title = {Decision-makers' perceptions of the value and impact of visual interactive modelling},
  volume = {27},
  issn = {0305-0483},
  url = {http://www.sciencedirect.com/science/article/pii/S0305048398000358},
  doi = {10.1016/S0305-0483(98)00035-8},
  abstract = {This article reports results from surveying decision makers who had used a visual, interactive (VI) model to aid their decision making. The survey was a follow-up to an earlier survey of modellers who had built at least one VI model. The model builders reported on their practical experience with VI model building, including their assessment of decision makers' reactions to their models. The present survey was conducted to sample decision makers directly, and the results generally confirm the high level of support and interest in VI models among decision makers.},
  timestamp = {2016-01-19T02:43:21Z},
  number = {2},
  journaltitle = {Omega},
  shortjournal = {Omega},
  author = {Bell, Peter C and Anderson, Chris K and Staples, D. Sandy and Elder, Mark},
  urldate = {2016-01-19},
  date = {1999-04},
  pages = {155--165},
  keywords = {modelling,Practice,simulation,user interfaces,Visual interactive models},
  file = {ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/VXK74NVR/S0305048398000358.html:;ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/X46WN96T/Bell et al. - 1999 - Decision-makers' perceptions of the value and impa.pdf:application/pdf}
}

@article{yilmazconstructivism2008,
  title = {Constructivism: {{Its}} theoretical underpinnings, variations, and implications for classroom instruction},
  timestamp = {2016-01-19T02:40:24Z},
  journaltitle = {Educational Horizons},
  shortjournal = {Educ. Horiz.},
  author = {Yilmaz, Kaya},
  date = {2008},
  pages = {161--172},
  file = {EJ798521.pdf:/Users/ben/Documents/zotero/storage/FR7TV86G/EJ798521.pdf:application/pdf}
}

@incollection{delisiimplications1999,
  location = {{Mahwah, NJ, US}},
  title = {Implications of {{Piagetian}} theory for peer learning},
  rights = {(c) 2012 APA, all rights reserved},
  isbn = {978-0-8058-2447-6 978-0-8058-2448-3},
  abstract = {Reviews the basic principles of Piaget's theory of cognitive development and its implications for peer learning. Special attention is focused on how peer learning relates to Piaget's model of constructivism through review of empirical work on the role of peer interactions in children's understanding of social justice and fairness, and children's logical thinking and spatial reasoning. The literature provides evidence that peer interactions can enhance learning outcomes in tasks within a developmental framework. Peer interactions also support cognitive change through dialogue and discussion more effectively than independent, individual work.},
  timestamp = {2016-01-19T02:38:27Z},
  booktitle = {Cognitive perspectives on peer learning},
  series = {The Rutgers Invitational Symposium On Education Series.},
  publisher = {{Lawrence Erlbaum Associates Publishers}},
  author = {De Lisi, Richard and Golbeck, Susan L.},
  editor = {O, A. M. and King, A.},
  date = {1999},
  pages = {3--37},
  keywords = {*Cognitive Development,*Constructivism,*Cooperative Learning,*Peer Relations,*Piaget (Jean),Peer Tutoring},
  file = {APA PsycNET Snapshot:/Users/ben/Documents/zotero/storage/AGX5HPKZ/1999-02359-001.html:}
}

@article{petracomputational2013,
  title = {A computational framework for infinite-dimensional {{Bayesian}} inverse problems: {{Part II}}. {{Stochastic Newton MCMC}} with application to ice sheet flow inverse problems},
  url = {http://arxiv.org/abs/1308.6221},
  shorttitle = {A computational framework for infinite-dimensional {{Bayesian}} inverse problems},
  abstract = {We address the numerical solution of infinite-dimensional inverse problems in the framework of Bayesian inference. In the Part I companion to this paper (arXiv.org:1308.1313), we considered the linearized infinite-dimensional inverse problem. Here in Part II, we relax the linearization assumption and consider the fully nonlinear infinite-dimensional inverse problem using a Markov chain Monte Carlo (MCMC) sampling method. To address the challenges of sampling high-dimensional pdfs arising from Bayesian inverse problems governed by PDEs, we build on the stochastic Newton MCMC method. This method exploits problem structure by taking as a proposal density a local Gaussian approximation of the posterior pdf, whose construction is made tractable by invoking a low-rank approximation of its data misfit component of the Hessian. Here we introduce an approximation of the stochastic Newton proposal in which we compute the low-rank-based Hessian at just the MAP point, and then reuse this Hessian at each MCMC step. We compare the performance of the proposed method to the original stochastic Newton MCMC method and to an independence sampler. The comparison of the three methods is conducted on a synthetic ice sheet inverse problem. For this problem, the stochastic Newton MCMC method with a MAP-based Hessian converges at least as rapidly as the original stochastic Newton MCMC method, but is far cheaper since it avoids recomputing the Hessian at each step. On the other hand, it is more expensive per sample than the independence sampler; however, its convergence is significantly more rapid, and thus overall it is much cheaper. Finally, we present extensive analysis and interpretation of the posterior distribution, and classify directions in parameter space based on the extent to which they are informed by the prior or the observations.},
  timestamp = {2016-01-12T03:02:21Z},
  author = {Petra, Noemi and Martin, James and Stadler, Georg and Ghattas, Omar},
  urldate = {2016-01-12},
  date = {2013-08-28},
  keywords = {35Q62; 62F15; 35R30; 35Q93; 65C40; 65C60; 49M15; 86A40,Mathematics - Numerical Analysis,Mathematics - Optimization and Control,Mathematics - Statistics Theory,Statistics - Computation,Statistics - Methodology},
  file = {arXiv.org Snapshot:/Users/ben/Documents/zotero/storage/8BJGV8G6/1308.html:;arXiv\:1308.6221 PDF:/Users/ben/Documents/zotero/storage/HDFIWQTX/Petra et al. - 2013 - A computational framework for infinite-dimensional.pdf:application/pdf},
  eprinttype = {arxiv},
  eprint = {1308.6221}
}

@article{bui-thanhcomputational2013,
  title = {A computational framework for infinite-dimensional {{Bayesian}} inverse problems. {{Part I}}: {{The}} linearized case, with application to global seismic inversion},
  url = {http://arxiv.org/abs/1308.1313},
  shorttitle = {A computational framework for infinite-dimensional {{Bayesian}} inverse problems. {{Part I}}},
  abstract = {We present a computational framework for estimating the uncertainty in the numerical solution of linearized infinite-dimensional statistical inverse problems. We adopt the Bayesian inference formulation: given observational data and their uncertainty, the governing forward problem and its uncertainty, and a prior probability distribution describing uncertainty in the parameter field, find the posterior probability distribution over the parameter field. The prior must be chosen appropriately in order to guarantee well-posedness of the infinite-dimensional inverse problem and facilitate computation of the posterior. Furthermore, straightforward discretizations may not lead to convergent approximations of the infinite-dimensional problem. And finally, solution of the discretized inverse problem via explicit construction of the covariance matrix is prohibitive due to the need to solve the forward problem as many times as there are parameters. Our computational framework builds on the infinite-dimensional formulation proposed by Stuart (A. M. Stuart, Inverse problems: A Bayesian perspective, Acta Numerica, 19 (2010), pp. 451-559), and incorporates a number of components aimed at ensuring a convergent discretization of the underlying infinite-dimensional inverse problem. The framework additionally incorporates algorithms for manipulating the prior, constructing a low rank approximation of the data-informed component of the posterior covariance operator, and exploring the posterior that together ensure scalability of the entire framework to very high parameter dimensions. We demonstrate this computational framework on the Bayesian solution of an inverse problem in 3D global seismic wave propagation with hundreds of thousands of parameters.},
  timestamp = {2016-01-11T04:36:31Z},
  author = {Bui-Thanh, Tan and Ghattas, Omar and Martin, James and Stadler, Georg},
  urldate = {2016-01-11},
  date = {2013-08-06},
  keywords = {35Q62; 62F15; 35R30; 35Q93; 65C60; 35L05,Mathematics - Numerical Analysis,Mathematics - Optimization and Control,Statistics - Computation,Statistics - Methodology},
  file = {arXiv\:1308.1313 PDF:/Users/ben/Documents/zotero/storage/37565G5N/Bui-Thanh et al. - 2013 - A computational framework for infinite-dimensional.pdf:application/pdf;arXiv.org Snapshot:/Users/ben/Documents/zotero/storage/XX552MEA/1308.html:},
  eprinttype = {arxiv},
  eprint = {1308.1313}
}

@article{petracomputational2014,
  title = {A {{Computational Framework}} for {{Infinite-Dimensional Bayesian Inverse Problems}}, {{Part II}}: {{Stochastic Newton MCMC}} with {{Application}} to {{Ice Sheet Flow Inverse Problems}}},
  volume = {36},
  issn = {1064-8275},
  url = {http://epubs.siam.org/doi/abs/10.1137/130934805},
  doi = {10.1137/130934805},
  shorttitle = {A {{Computational Framework}} for {{Infinite-Dimensional Bayesian Inverse Problems}}, {{Part II}}},
  abstract = {We address the numerical solution of infinite-dimensional inverse problems in the framework of Bayesian inference. In Part I of this paper {[}T. Bui-Thanh, O. Ghattas, J. Martin, and G. Stadler, SIAM J. Sci. Comput., 35 (2013), pp. A2494--A2523] we considered the linearized infinite-dimensional inverse problem. In Part II, we relax the linearization assumption and consider the fully nonlinear infinite-dimensional inverse problem using a Markov chain Monte Carlo (MCMC) sampling method. To address the challenges of sampling high-dimensional probability density functions (pdfs) arising upon discretization of Bayesian inverse problems governed by PDEs, we build upon the stochastic Newton MCMC method. This method exploits problem structure by taking as a proposal density a local Gaussian approximation of the posterior pdf, whose covariance operator is given by the inverse of the local Hessian of the negative log posterior pdf. The construction of the covariance is made tractable by invoking a low-rank approximation of the data misfit component of the Hessian. Here we introduce an approximation of the stochastic Newton proposal in which we compute the low-rank-based Hessian at just the maximum a posteriori (MAP) point, and then reuse this Hessian at each MCMC step. We compare the performance of the proposed method to the original stochastic Newton MCMC method and to an independence sampler. The comparison of the three methods is conducted on a synthetic ice sheet inverse problem. For this problem, the stochastic Newton MCMC method with a MAP-based Hessian converges at least as rapidly as the original stochastic Newton MCMC method, but is far cheaper since it avoids recomputing the Hessian at each step. On the other hand, it is more expensive per sample than the independence sampler; however, its convergence is significantly more rapid, and thus overall it is much cheaper. Finally, we present extensive analysis and interpretation of the posterior distribution and classify directions in parameter space based on the extent to which they are informed by the prior or the observations.},
  timestamp = {2016-01-11T04:35:29Z},
  number = {4},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  author = {Petra, N. and Martin, J. and Stadler, G. and Ghattas, O.},
  urldate = {2016-01-11},
  date = {2014-01-01},
  pages = {A1525--A1555},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/BXTNGURV/130934805.html:}
}

@incollection{bieglerintroduction2010,
  title = {Introduction},
  rights = {Copyright \%C2\%A9 2011 John Wiley \& Sons, Ltd},
  isbn = {978-0-470-68585-3},
  url = {http://onlinelibrary.wiley.com.virtual.anu.edu.au/doi/10.1002/9780470685853.ch1/summary},
  abstract = {This chapter contains sections titled:

* Introduction
* Statistical Methods
* Approximation Methods
* Kalman Filtering
* Optimization},
  timestamp = {2016-01-07T21:25:44Z},
  langid = {english},
  booktitle = {Large-{{Scale Inverse Problems}} and {{Quantification}} of {{Uncertainty}}},
  publisher = {{John Wiley \& Sons, Ltd}},
  editor = {Biegler, Lorenz and Biros, George and Ghattas, Omar and Heinkenschloss, tthias and Keyes, David and Banillick, and Youssefrzouk, and Tenorio, Luis and Waanders, Bart van Bloemen and Willcox, Karen},
  urldate = {2016-01-07},
  date = {2010},
  pages = {1--7},
  keywords = {approximation techniques - replacing forward model with inexpensive surrogates,computational methods - for large-scale inverse problems,crucial unmet need for scalable numerical algorithm development - and large-scale inverse problem solution,earth's subsurface mapping and seismic waves,ill-posed inverse problems - in science and engineering,inverse problems and statistical characterizations - uncertainties modeled randomly,inverse problems; determining input - or given noisy data,inverse problem solving - estimating unknown objects from indirect noisy observations,precursors to quantification of uncertainties - prediction and decision-making,statistical methods and approximation methods},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/KRQT6A8V/summary.html:}
}

@article{litvinenkoinverse2013,
  title = {Inverse problems and uncertainty quantification},
  url = {http://arxiv.org/abs/1312.5048},
  abstract = {In a Bayesian setting, inverse problems and uncertainty quantification (UQ) - the propagation of uncertainty through a computational (forward) model - are strongly connected. In the form of conditional expectation the Bayesian update becomes computationally attractive. This is especially the case as together with a functional or spectral approach for the forward UQ there is no need for time-consuming and slowly convergent Monte Carlo sampling. The developed sampling-free non-linear Bayesian update is derived from the variational problem associated with conditional expectation. This formulation in general calls for further discretisation to make the computation possible, and we choose a polynomial approximation. After giving details on the actual computation in the framework of functional or spectral approximations, we demonstrate the workings of the algorithm on a number of examples of increasing complexity. At last, we compare the linear and quadratic Bayesian update on the small but taxing example of the chaotic Lorenz 84 model, where we experiment with the influence of different observation or measurement operators on the update.},
  timestamp = {2016-01-07T21:24:39Z},
  author = {Litvinenko, Alexander and Matthies, Hermann G.},
  urldate = {2016-01-07},
  date = {2013-12-18},
  keywords = {62F15; 65N21; 62P30; 60H15; 60H25; 74G75; 80A23; 74C05,G.1.8,G.3,J.2,Mathematics - Numerical Analysis},
  file = {arXiv.org Snapshot:/Users/ben/Documents/zotero/storage/BIMS393N/1312.html:;arXiv\:1312.5048 PDF:/Users/ben/Documents/zotero/storage/RR5GX487/Litvinenko and Matthies - 2013 - Inverse problems and uncertainty quantification.pdf:application/pdf},
  eprinttype = {arxiv},
  eprint = {1312.5048}
}

@article{jakemannumerical2010,
  title = {Numerical approach for quantification of epistemic uncertainty},
  volume = {229},
  issn = {0021-9991},
  url = {http://www.sciencedirect.com/science/article/pii/S0021999110001130},
  doi = {10.1016/j.jcp.2010.03.003},
  abstract = {In the field of uncertainty quantification, uncertainty in the governing equations may assume two forms: aleatory uncertainty and epistemic uncertainty. Aleatory uncertainty can be characterised by known probability distributions whilst epistemic uncertainty arises from a lack of knowledge of probabilistic information. While extensive research efforts have been devoted to the numerical treatment of aleatory uncertainty, little attention has been given to the quantification of epistemic uncertainty. In this paper, we propose a numerical framework for quantification of epistemic uncertainty. The proposed methodology does not require any probabilistic information on uncertain input parameters. The method only necessitates an estimate of the range of the uncertain variables that encapsulates the true range of the input variables with overwhelming probability. To quantify the epistemic uncertainty, we solve an encapsulation problem, which is a solution to the original governing equations defined on the estimated range of the input variables. We discuss solution strategies for solving the encapsulation problem and the sufficient conditions under which the numerical solution can serve as a good estimator for capturing the effects of the epistemic uncertainty. In the case where probability distributions of the epistemic variables become known a posteriori, we can use the information to post-process the solution and evaluate solution statistics. Convergence results are also established for such cases, along with strategies for dealing with mixed aleatory and epistemic uncertainty. Several numerical examples are presented to demonstrate the procedure and properties of the proposed methodology.},
  timestamp = {2016-01-07T04:16:27Z},
  number = {12},
  journaltitle = {Journal of Computational Physics},
  journal = {Journal of Computational Physics},
  year = {2010},
  shortjournal = {Journal of Computational Physics},
  author = {Jakeman, John and Eldred, Michael and Xiu, Dongbin},
  urldate = {2016-01-07},
  date = {2010-06-20},
  pages = {4648--4663},
  keywords = {Encapsulation problem,Epistemic uncertainty,Generalized polynomial chaos,Stochastic collocation,Uncertainty quantification},
  file = {ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/8QFMZZAB/S0021999110001130.html:;ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/9PCB7M5R/Jakeman et al. - 2010 - Numerical approach for quantification of epistemic.pdf:application/pdf}
}

@article{yuenonline2016,
  title = {Online updating and uncertainty quantification using nonstationary output-only measurement},
  volume = {66--67},
  issn = {0888-3270},
  url = {http://www.sciencedirect.com/science/article/pii/S0888327015002721},
  doi = {10.1016/j.ymssp.2015.05.019},
  abstract = {Extended Kalman filter (EKF) is widely adopted for state estimation and parametric identification of dynamical systems. In this algorithm, it is required to specify the covariance matrices of the process noise and measurement noise based on prior knowledge. However, improper assignment of these noise covariance matrices leads to unreliable estimation and misleading uncertainty estimation on the system state and model parameters. Furthermore, it may induce diverging estimation. To resolve these problems, we propose a Bayesian probabilistic algorithm for online estimation of the noise parameters which are used to characterize the noise covariance matrices. There are three major appealing features of the proposed approach. First, it resolves the divergence problem in the conventional usage of EKF due to improper choice of the noise covariance matrices. Second, the proposed approach ensures the reliability of the uncertainty quantification. Finally, since the noise parameters are allowed to be time-varying, nonstationary process noise and/or measurement noise are explicitly taken into account. Examples using stationary/nonstationary response of linear/nonlinear time-varying dynamical systems are presented to demonstrate the efficacy of the proposed approach. Furthermore, comparison with the conventional usage of EKF will be provided to reveal the necessity of the proposed approach for reliable model updating and uncertainty quantification.},
  timestamp = {2015-12-21T00:06:38Z},
  journaltitle = {Mechanical Systems and Signal Processing},
  shortjournal = {Mechanical Systems and Signal Processing},
  author = {Yuen, Ka-Veng and Kuok, Sin-Chi},
  urldate = {2015-12-21},
  date = {2016-01},
  pages = {62--77},
  keywords = {Bayesian inference,Extended Kalman filter,Noise covariance matrices,Nonstationary response,structural health monitoring,System identification},
  file = {ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/MFKN4QRX/Yuen and Kuok - 2016 - Online updating and uncertainty quantification usi.pdf:application/pdf;ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/Z3TXVVQW/S0888327015002721.html:}
}

@article{sununcertainty2014,
  title = {Uncertainty quantification of microclimate variables in building energy models},
  volume = {7},
  issn = {1940-1493},
  url = {http://dx.doi.org/10.1080/19401493.2012.757368},
  doi = {10.1080/19401493.2012.757368},
  abstract = {The last decade has seen a surge in the need for uncertainty analysis (UA) for building energy assessment. The rigorous determination of uncertainty in model parameters is a vital but often overlooked part of UA. To undertake this, one has to turn one's attention to a thriving area in engineering statistics that focuses on uncertainty quantification (UQ) for short. This paper applies dedicated methods and theories that are emerging in this area of statistics to the field of building energy models, and specifically to the microclimate variables embedded in them. We argue that knowing the uncertainty in these variables is a vital prerequisite for ensuing UA of whole building behaviour. Indeed, significant discrepancies have been observed between the predicted and measured state variables of building microclimates. This paper uses a set of approaches from the growing UQ arsenal, mostly regression-based methods, to develop statistical models that quantify the uncertainties in the following most significant microclimate variables: local temperature, wind speed, wind pressure and solar irradiation. These are the microclimate variables used by building energy models to define boundary conditions that encapsulate the interaction of the building with the surrounding physical environment. Although our analysis is generically applicable to any of the current energy models, we will base our UQ examples on the energy model used in EnergyPlus.},
  timestamp = {2015-12-17T00:46:13Z},
  number = {1},
  journaltitle = {Journal of Building Performance Simulation},
  shortjournal = {J. Build. Perform. Simul.},
  author = {Sun, Yuming and Heo, Yeonsook and Tan, Matthias and Xie, Huizhi and Wu, C. F. Jeff and Augenbroe, Godfried},
  urldate = {2015-12-17},
  date = {2014-01-02},
  pages = {17--32},
  file = {Full Text PDF:/Users/ben/Documents/zotero/storage/6NE3R5JW/Sun et al. - 2014 - Uncertainty quantification of microclimate variabl.pdf:application/pdf;Snapshot:/Users/ben/Documents/zotero/storage/88ZQ8G9T/19401493.2012.html:}
}

@inproceedings{bui-thanhextremescale2012,
  location = {{Los Alamitos, CA, USA}},
  title = {Extreme-scale {{UQ}} for {{Bayesian Inverse Problems Governed}} by {{PDEs}}},
  isbn = {978-1-4673-0804-5},
  url = {http://dl.acm.org/citation.cfm?id=2388996.2389000},
  abstract = {Quantifying uncertainties in large-scale simulations has emerged as the central challenge facing CS\&E. When the simulations require supercomputers, and uncertain parameter dimensions are large, conventional UQ methods fail. Here we address uncertainty quantification for large-scale inverse problems in a Bayesian inference framework: given data and model uncertainties, find the pdf describing parameter uncertainties. To overcome the curse of dimensionality of conventional methods, we exploit the fact that the data are typically informative about low-dimensional manifolds of parameter space to construct low rank approximations of the covariance matrix of the posterior pdf via a matrix-free randomized method. We obtain a method that scales independently of the forward problem dimension, the uncertain parameter dimension, the data dimension, and the number of cores. We apply the method to the Bayesian solution of an inverse problem in 3D global seismic wave propagation with over one million uncertain earth model parameters, 630 million wave propagation unknowns, on up to 262K cores, for which we obtain a factor of over 2000 reduction in problem dimension. This makes UQ tractable for the inverse problem.},
  timestamp = {2015-12-17T00:43:00Z},
  booktitle = {Proceedings of the {{International Conference}} on {{High Performance Computing}}, {{Networking}}, {{Storage}} and {{Analysis}}},
  series = {SC '12},
  publisher = {{IEEE Computer Society Press}},
  author = {Bui-Thanh, Tan and Burstedde, Carsten and Ghattas, Omar and Martin, James and Stadler, Georg and Wilcox, Lucas C.},
  urldate = {2015-12-17},
  date = {2012},
  pages = {3:1--3:11},
  file = {ACM Full Text PDF:/Users/ben/Documents/zotero/storage/ZM94G7HH/Bui-Thanh et al. - 2012 - Extreme-scale UQ for Bayesian Inverse Problems Gov.pdf:application/pdf}
}

@inproceedings{nguyennon2015,
  title = {Non instrusive uncertainty quantification method for models with a high number of parameters-{{Application}} to a magnetoelectric sensor},
  timestamp = {2015-12-17T00:39:46Z},
  publisher = {{Compumag}},
  author = {Nguyen, T. T. and Mac, D. H. and Clénet, S.},
  date = {2015},
  file = {PA6_PA6-14 Clenet-Non instrusive uncertainty quantification method for models with a high number.pdf:/Users/ben/Documents/zotero/storage/TEW9SFW8/PA6_PA6-14 Clenet-Non instrusive uncertainty quantification method for models with a high number.pdf:application/pdf}
}

@article{sankararamanuncertainty2011,
  title = {Uncertainty quantification in structural damage diagnosis},
  volume = {18},
  rights = {Copyright \%C2\%A9 2010 John Wiley \& Sons, Ltd.},
  issn = {1545-2263},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/stc.400/abstract},
  doi = {10.1002/stc.400},
  abstract = {This paper develops methods for the quantification of uncertainty in each of the three steps of damage diagnosis (detection, localization and quantification), in the context of continuous online monitoring. A model-based approach is used for diagnosis. Sources of uncertainty include physical variability, measurement uncertainty and model errors. Damage detection is based on residuals between nominal and damaged system-level responses, using statistical hypothesis testing whose uncertainty can be captured easily. Localization is based on the comparison of damage signatures derived from the system model. A metric based on least squares is proposed to assess the uncertainty in damage localization, when the damage signatures fail to localize the damage uniquely. The uncertainty in damage quantification is evaluated through statistical non-linear regression, resulting in confidence bounds for the damage parameter. The uncertainties in damage detection, isolation and quantification are combined to quantify the overall uncertainty in diagnosis. The proposed methods are illustrated using two types of example problems, a structural frame and a hydraulic actuation system. Copyright © 2010 John Wiley \& Sons, Ltd.},
  timestamp = {2015-12-17T00:38:05Z},
  langid = {english},
  number = {8},
  journaltitle = {Structural Control and Health Monitoring},
  shortjournal = {Struct. Control Health Monit.},
  author = {Sankararaman, Shankar and Mahadevan, Sankaran},
  urldate = {2015-12-17},
  date = {2011-12-01},
  pages = {807--824},
  keywords = {bond graph,confidence intervals,damage detection,damage diagnosis,F-statistic,inverse problems,non-linear regression,structural health monitoring,Uncertainty quantification},
  file = {Full Text PDF:/Users/ben/Documents/zotero/storage/MVC45CHJ/Sankararaman and Mahadevan - 2011 - Uncertainty quantification in structural damage di.pdf:application/pdf;Snapshot:/Users/ben/Documents/zotero/storage/XRMSWJ4G/full.html:}
}

@article{galballynonlinear2010,
  title = {Non‐linear model reduction for uncertainty quantification in large‐scale inverse problems},
  volume = {81},
  timestamp = {2015-12-17T00:34:31Z},
  number = {12},
  journaltitle = {International journal for numerical methods in engineering},
  shortjournal = {Int. J. Numer. Methods Eng.},
  author = {Galbally, David and Fidkowski, K. and Willcox, K. and Ghattas, O.},
  date = {2010},
  pages = {1581--1608},
  file = {Galbally_et_al-2010-International_Journal_for_Numerical_Methods_in_Engineering.pdf:/Users/ben/Documents/zotero/storage/49FKAS3R/Galbally_et_al-2010-International_Journal_for_Numerical_Methods_in_Engineering.pdf:application/pdf}
}

@article{beck_updating1998,
  title = {Updating {{Models}} and {{Their Uncertainties}}. {{I}}: {{Bayesian Statistical Framework}}},
  volume = {124},
  issn = {0733-9399},
  url = {http://dx.doi.org/10.1061/(ASCE)0733-9399(1998)124:4(455)},
  doi = {10.1061/(ASCE)0733-9399(1998)124:4(455)},
  timestamp = {2015-12-17T00:18:47Z},
  number = {4},
  journaltitle = {Journal of Engineering Mechanics},
  shortjournal = {J. Eng. Mech.},
  author = {Beck, J. and Katafygiotis, L.},
  urldate = {2015-12-16},
  date = {1998-04-01},
  pages = {455--461},
  file = {updating_models_and_their_uncertaintiespdf.pdf:/Users/ben/Documents/zotero/storage/GVP5VUCH/updating_models_and_their_uncertaintiespdf.pdf:application/pdf}
}



@article{lipshitz_taking2001,
  title = {Taking stock of naturalistic decision making},
  volume = {14},
  rights = {Copyright \%C2\%A9 2001 John Wiley \& Sons, Ltd.},
  issn = {1099-0771},
  url = {http://onlinelibrary.wiley.com.virtual.anu.edu.au/doi/10.1002/bdm.381/abstract},
  doi = {10.1002/bdm.381},
  abstract = {We review the progress of naturalistic decision making (NDM) in the decade since the first conference on the subject in 1989. After setting out a brief history of NDM we identify its essential characteristics and consider five of its main contributions: recognition-primed decisions, coping with uncertainty, team decision making, decision errors, and methodology. NDM helped identify important areas of inquiry previously neglected (e.g. the use of expertise in sizing up situations and generating options), it introduced new models, conceptualizations, and methods, and recruited applied investigators into the field. Above all, NDM contributed a new perspective on how decisions (broadly defined as committing oneself to a certain course of action) are made. NDM still faces significant challenges, including improvement of the quantity and rigor of its empirical research, and confirming the validity of its prescriptive models. Copyright \%C2\%A9 2001 John Wiley \& Sons, Ltd.},
  timestamp = {2016-01-26T03:44:33Z},
  langid = {english},
  number = {5},
  journaltitle = {Journal of Behavioral Decision Making},
  shortjournal = {J. Behav. Decis. Making},
  author = {Lipshitz, Raanan and Klein, Gary and Orasanu, Judith and Salas, Eduardo},
  urldate = {2016-01-26},
  date = {2001-12-01},
  pages = {331--352},
  keywords = {coping with uncertainty,decision errors,decision training,naturalistic decision making,recognition-primed decisions,research methodology,team decision making},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/B8U3NH78/abstract.html:;Full Text PDF:/Users/ben/Documents/zotero/storage/NNCV4DCQ/Lipshitz et al. - 2001 - Taking stock of naturalistic decision making.pdf:application/pdf}
}


@article{erricowhat1997,
  title = {What {{Is}} an {{Adjoint Model}}?},
  volume = {78},
  issn = {0003-0007},
  url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0477(1997)078%3C2577%3AWIAAM%3E2.0.CO%3B2},
  doi = {10.1175/1520-0477(1997)078<2577:WIAAM>2.0.CO;2},
  abstract = {Abstract Adjoint models are powerful tools for many studies that require an estimate of sensitivity of model output (e.g., a forecast) with respect to input. Actual fields of sensitivity are produced directly and efficiently, which can then be used in a variety of applications, including data assimilation, parameter estimation, stability analysis, and synoptic studies. The use of adjoint models as tools for sensitivity analysis is described here using some simple mathematics. An example of sensitivity fields is presented along with a short description of adjoint applications. Limitations of the applications are discussed and some speculations about the future of adjoint models are offered.},
  timestamp = {2014-12-23T23:32:58Z},
  number = {11},
  journaltitle = {Bulletin of the American Meteorological Society},
  shortjournal = {Bull. Amer. Meteor. Soc.},
  author = {Errico, Ronald M.},
  urldate = {2014-12-23},
  date = {1997-11-01},
  pages = {2577--2591},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/6QT9IHIW/1520-0477(1997)0782577WIAAM2.0.html:;Full Text PDF:/Users/ben/Documents/zotero/storage/A7HB6S3I/Errico - 1997 - What Is an Adjoint Model.pdf:application/pdf}
}



@article{roycomprehensive2011,
  title = {A comprehensive framework for verification, validation, and uncertainty quantification in scientific computing},
  volume = {200},
  issn = {0045-7825},
  url = {http://www.sciencedirect.com/science/article/pii/S0045782511001290},
  doi = {10.1016/j.cma.2011.03.016},
  abstract = {An overview of a comprehensive framework is given for estimating the predictive uncertainty of scientific computing applications. The framework is comprehensive in the sense that it treats both types of uncertainty (aleatory and epistemic), incorporates uncertainty due to the mathematical form of the model, and it provides a procedure for including estimates of numerical error in the predictive uncertainty. Aleatory (random) uncertainties in model inputs are treated as random variables, while epistemic (lack of knowledge) uncertainties are treated as intervals with no assumed probability distributions. Approaches for propagating both types of uncertainties through the model to the system response quantities of interest are briefly discussed. Numerical approximation errors (due to discretization, iteration, and computer round off) are estimated using verification techniques, and the conversion of these errors into epistemic uncertainties is discussed. Model form uncertainty is quantified using (a) model validation procedures, i.e., statistical comparisons of model predictions to available experimental data, and (b) extrapolation of this uncertainty structure to points in the application domain where experimental data do not exist. Finally, methods for conveying the total predictive uncertainty to decision makers are presented. The different steps in the predictive uncertainty framework are illustrated using a simple example in computational fluid dynamics applied to a hypersonic wind tunnel.},
  timestamp = {2016-01-26T06:25:27Z},
  number = {25-28},
  journaltitle = {Computer Methods in Applied Mechanics and Engineering},
  shortjournal = {Computer Methods in Applied Mechanics and Engineering},
  author = {Roy, Christopher J. and Oberkampf, William L.},
  urldate = {2016-01-26},
  date = {2011-06-15},
  pages = {2131--2144},
  keywords = {Computational simulation,modeling,Uncertainty quantification,Validation,Verification},
  file = {ScienceDirect Full Text PDF:/Users/ben/Documents/zotero/storage/CFFHW9Q2/Roy and Oberkampf - 2011 - A comprehensive framework for verification, valida.pdf:application/pdf;ScienceDirect Snapshot:/Users/ben/Documents/zotero/storage/Q4BSVAT4/S0045782511001290.html:}
}

@article{Jakeman2015,
title = "Enhancing adaptive sparse grid approximations and improving refinement strategies using adjoint-based a posteriori error estimates ",
journal = "Journal of Computational Physics ",
volume = "280",
number = "",
pages = "54 - 71",
year = "2015",
note = "",
issn = "0021-9991",
doi = "http://dx.doi.org/10.1016/j.jcp.2014.09.014",
url = "http://www.sciencedirect.com/science/article/pii/S0021999114006500",
author = "J.D. Jakeman and T. Wildey",
keywords = "Uncertainty quantification",
keywords = "A posteriori error estimation",
keywords = "Sparse grids",
keywords = "Stochastic collocation",
keywords = "Adaptivity "
}

@incollection{FranzelinDiehlPfluger2014,
  author = {F.~Franzelin and P.~Diehl and D.~Pfl\"uger},
  title = {Non-intrusive Uncertainty Quantification with Sparse Grids
		  for Multivariate Peridynamic Simulations},
  booktitle = {Meshfree Methods for Partial Differential Equations
		  {VII}},
  series = {Lecture Notes in Computational Science and Engineering},
  publisher = {Springer},
  year = {2014},
  editor = {M.~Griebel and M.~A.~Schweitzer},
  volume = {100},
  annote = {ag-schweitzer,series,inspreprint},
  note = {{Also available as INS Preprint No. 1408}},
  inspreprintnum = {1408},
  pdf = {http://schweitzer.ins.uni-bonn.de/publications/pdfs/diehl_franzelin_pfl\%C3\%BCger_iwmm2013_preprint.pdf}
}

@incollection{Peherstorfer2013,
author={Peherstorfer, Benjamin and Zimmer, Stefan and Bungartz, 
Hans-Joachim},
editor={Garcke, Jochen and Griebel, Michael},
title="Model Reduction with the Reduced Basis Method and Sparse Grids",
booktitle="Sparse Grids and Applications",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="223--242",
isbn="978-3-642-31703-3",
doi="10.1007/978-3-642-31703-3_11",
url="http://dx.doi.org/10.1007/978-3-642-31703-3_11"
}


@inproceedings{ryggunified2006,
  title = {A {{Unified Model}} of {{Batch}} and {{Interactive Scientific Workflow}} and {{Its Implementation Using Windows Workflow}}},
  doi = {10.1109/E-SCIENCE.2006.261120},
  abstract = {Workflow is a key technology for eScience. It enables scientific tools to be composed and the resulting workflows to be managed. Workflow and most other computing tools typically distinguish batch from interactive operation. This distinction is ill-suited to scientific experimentation which typically starts interactively and then may progress to batch operation for larger or repeated runs of experiments. In this paper we present a scientific workflow model which unifies batch and interactive operation. This supports seamless experimentation by scientists. The model is implemented in a web based environment through the Microsoft Windows Workflow system and features a novel model for workflow components.},
  eventtitle = {Second IEEE International Conference on e-Science and Grid Computing, 2006. e-Science '06},
  timestamp = {2015-01-06T02:40:33Z},
  booktitle = {Second {{IEEE International Conference}} on e-{{Science}} and {{Grid Computing}}, 2006. e-{{Science}} '06},
  author = {Rygg, A. and Sumitomo, J. and Roe, P.},
  date = {2006-12},
  pages = {36--36},
  keywords = {Australia,Automation,Collaborative work,Computer vision,Humans,Large-scale systems,Mathematical model,Pipelines,Production systems,Programming profession},
  file = {IEEE Xplore Abstract Record:/Users/ben/Documents/zotero/storage/G3ERN3ZN/abs_all.html:;IEEE Xplore Full Text PDF:/Users/ben/Documents/zotero/storage/SR7XBDN3/Rygg et al. - 2006 - A Unified Model of Batch and Interactive Scientifi.pdf:application/pdf}
}


@article{liuEffects2014,
  title = {The {{Effects}} of {{Interactive Latency}} on {{Exploratory Visual Analysis}}},
  volume = {20},
  issn = {1077-2626},
  doi = {10.1109/TVCG.2014.2346452},
  abstract = {To support effective exploration, it is often stated that interactive visualizations should provide rapid response times. However, the effects of interactive latency on the process and outcomes of exploratory visual analysis have not been systematically studied. We present an experiment measuring user behavior and knowledge discovery with interactive visualizations under varying latency conditions. We observe that an additional delay of 500ms incurs significant costs, decreasing user activity and data set coverage. Analyzing verbal data from think-aloud protocols, we find that increased latency reduces the rate at which users make observations, draw generalizations and generate hypotheses. Moreover, we note interaction effects in which initial exposure to higher latencies leads to subsequently reduced performance in a low-latency setting. Overall, increased latency causes users to shift exploration strategy, in turn affecting performance. We discuss how these results can inform the design of interactive analysis tools.},
  timestamp = {2015-08-04T06:00:37Z},
  number = {12},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  year= {2014},
  shortjournal = {IEEE Trans. Vis. Comput. Graph.},
  author = {Liu, Zhicheng and Heer, J.},
  date = {2014-12},
  pages = {2122--2131},
  keywords = {data analysis,Data mining,Data visualization,exploratory analysis,exploratory visual analysis,Image color analysis,Interaction,interactive analysis tools,interactive latency effects,Interactive services,interactive systems,interactive visualization,knowledge discovery,latency,scalability,think-aloud protocols,user behavior,user performance,verbal analysis,verbal data analysis,Visual analytics,Visualization},
  file = {IEEE Xplore Abstract Record:/Users/ben/Documents/zotero/storage/DGDV2VZ4/abs_all.html:;Liu_Heer_2014_The Effects of Interactive Latency on Exploratory Visual Analysis.pdf:/Users/ben/Documents/zotero/storage/WRG2Q749/Liu_Heer_2014_The Effects of Interactive Latency on Exploratory Visual Analysis.pdf:application/pdf}
}



@book{le_maitre_introduction_2010,
  title = {Introduction: {{Uncertainty Quantification}} and {{Propagation}}},
  isbn = {90-481-3519-2},
  timestamp = {2016-02-01T07:33:17Z},
  publisher = {{Springer}},
  author = {Le Maître, Olivier P. and Knio, Omar M.},
  date = {2010}
}



@article{colellaparticipatory2000,
  title = {Participatory {{Simulations}}: {{Building Collaborative Understanding Through Immersive Dynamic Modeling}}},
  volume = {9},
  issn = {1050-8406},
  url = {http://dx.doi.org/10.1207/S15327809JLS0904_4},
  doi = {10.1207/S15327809JLS0904_4},
  shorttitle = {Participatory {{Simulations}}},
  abstract = {This article explores a new way to help people understand complex, dynamic systems. Participatory simulations plunge learners into life-sized, computer-supported simulations, creating new paths to scientific understanding. By wearing small, communicating computers called Thinking Tags, students are transformed into players in a large-scale microworld. Like classic microworlds, participatory simulations create a scenario, mediated by a set of underlying rules, that enables inquiry and experimentation. In addition, these new activities allow students to "dive into" a learning environment and directly engage with the complex system at hand. This article describes and analyzes a set of participatory simulations that were conducted with a group of high school biology students. The students' experiences are tracked from their initial encounter with an immersive simulation through their exploration of the system and final description of its underlying rules. The article explores the educational potential of participatory simulations. The results of this pilot study suggest an opportunity to further investigate the role that personal experience can play in developing inquiry skills and scientific understanding.},
  timestamp = {2015-08-04T01:47:17Z},
  number = {4},
  journaltitle = {Journal of the Learning Sciences},
  shortjournal = {J. Learn. Sci.},
  author = {Colella, Vanessa},
  urldate = {2015-08-04},
  date = {2000-10-01},
  pages = {471--500},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/2WMHSHFK/S15327809JLS0904_4.html:;Colella_2000_Participatory Simulations.pdf:/Users/ben/Documents/zotero/storage/JXWD5ZKZ/Colella_2000_Participatory Simulations.pdf:application/pdf}
}



@inproceedings{luisSpporting2014,
  location = {{New York, NY, USA}},
  title = {Supporting {{Learners}} in {{Collecting}} and {{Exploring Data}} from {{Immersive Simulations}} in {{Collective Inquiry}}},
  isbn = {978-1-4503-2473-1},
  url = {http://doi.acm.org/10.1145/2556288.2557162},
  doi = {10.1145/2556288.2557162},
  abstract = {Digitally augmented physical spaces (e.g., smart classrooms) offer opportunities to engage students in novel and potentially transformative learning experiences. This paper presents an immersive rainforest simulation and collective inquiry activity where students collect observational data from the environment and explore their peers' data through large visualization displays and personal mobile devices. Two iterations of the design were tested, which resulted in higher quality student explanations constructed. Images were found to be an important source of evidence for the explanations, more so than text-only evidence. We also found that patterns of collective ideas influenced student performance, and that visualizations, as ambient or plenary displays, supported both teacher and students in reviewing patterns of collected data.},
  timestamp = {2015-08-04T01:48:30Z},
  booktitle = {Proceedings of the {{32Nd Annual ACM Conference}} on {{Human Factors}} in {{Computing Systems}}},
  series = {CHI '14},
  publisher = {{ACM}},
  author = {Lui, Michelle and Kuhn, Alex C. and Acosta, Alisa and Quintana, Chris and Slotta, James D.},
  urldate = {2015-08-04},
  date = {2014},
  pages = {2103--2112},
  keywords = {digitally augmented physical spaces,large displays,mobile computing,multi-device environments,science inquiry,smart classroom,visualizations},
  file = {Lui et al_2014_Supporting Learners in Collecting and Exploring Data from Immersive Simulations.pdf:/Users/ben/Documents/zotero/storage/3X39F2EV/Lui et al_2014_Supporting Learners in Collecting and Exploring Data from Immersive Simulations.pdf:application/pdf}
}



@book{ungar_self1987,
  title = {Self: {{The}} power of simplicity},
  volume = {22},
  isbn = {0-89791-247-0},
  url = {http://dl.acm.org/citation.cfm?id=38807.38828},
  abstract = {Abstract Self is a new object-oriented language for exploratory programming based on a small number of simple and concrete ideas: prototypes, slots, and behavior. Prototypes combine inheritance and instantiation to provide a framework that is simpler and more ...},
  pagetotal = {227},
  timestamp = {2014-12-22T00:19:10Z},
  series = {ACM SIGPLAN Notices},
  publisher = {{ACM}},
  author = {Ungar, David and Smith, Randall B},
  date = {1987-12-01},
  file = {ACM SIGPLAN Notices 1987 Ungar-1:/Users/ben/Documents/zotero/storage/QX93VDQC/ACM SIGPLAN Notices 1987 Ungar-1.pdf:application/pdf}
}

@article{sorensen2010programming,
  title={Programming with time: cyber-physical programming with impromptu},
  author={Sorensen, Andrew and Gardner, Henry},
  journal={ACM Sigplan Notices},
  volume={45},
  number={10},
  pages={822--834},
  year={2010},
  publisher={ACM}
}

@inproceedings{sorensenimpromptu2005,
  title = {Impromptu: {{An}} interactive programming environment for composition and performance},
  eventtitle = {ACMC '05},
  timestamp = {2014-12-22T00:18:53Z},
  booktitle = {{{ACMC}} '05},
  author = {Sorensen, Andrew},
  date = {2005-01-01},
  file = {ACMC '05 2005 Sorensen-1:/Users/ben/Documents/zotero/storage/MP4CKP37/ACMC '05 2005 Sorensen-1.pdf:application/pdf}
}

@article{kinkeldey2015evaluating,
  title={Evaluating the effect of visually represented geodata uncertainty on decision-making: systematic review, lessons learned, and recommendations},
  author={Kinkeldey, Christoph and MacEachren, Alan M and Riveiro, Maria and Schiewe, Jochen},
  journal={Cartography and Geographic Information Science},
  pages={1--21},
  year={2015},
  publisher={Taylor \& Francis}
}

@misc{sorensenExtempore,
  title = {Extempore},
  url = {http://extempore.moso.com.au/},
  timestamp = {2014-12-22T00:19:20Z},
  titleaddon = {extempore.moso.com.au},
  author = {Sorensen, Andrew}
}



@misc{amazonAws,
  author={Amazon},
  title = {Amazon {{Web Services}} ({{AWS}}) - {{Cloud Computing Services}}},
  url = {//aws.amazon.com/},
  abstract = {Amazon Web Services offers reliable, scalable, and inexpensive cloud computing services. Free to join, pay only for what you use.},
   year={2016},
  key={Amazon WebServices},
  timestamp = {2016-02-04T04:16:22Z},
  titleaddon = {Amazon Web Services, Inc.},
  urldate = {2016-02-04},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/FV63XJQ6/aws.amazon.com.html:}
}

@misc{nciCloud,
  author={NCI~NF},
  title = {{{NCI Cloud Computing}}},
  url = {http://nci.org.au/systems-services/national-facility/cloud-computing/},
  abstract = {Australia's high-performance supercomputer, cloud and data repository. Funded by ANU, CSIRO, Bureau of Meteorology, Geoscience Australia and the ARC},
  timestamp = {2016-02-04T04:15:10Z},
  key={National Computational Infrastructure},
  titleaddon = {National Computational Infrastructure},
  urldate = {2016-02-04},
  file = {Snapshot:/Users/ben/Documents/zotero/storage/UD6N5MAG/cloud-computing.html:}
}



@article{PeherstorferWillcox2015,
author = {Benjamin Peherstorfer and Karen Willcox},
title = {Online Adaptive Model Reduction for Nonlinear Systems via Low-Rank Updates},
journal = {SIAM Journal on Scientific Computing},
volume = {37},
number = {4},
pages = {A2123-A2150},
year = {2015},
doi = {10.1137/140989169},
URL = {http://dx.doi.org/10.1137/140989169},
eprint = {http://dx.doi.org/10.1137/140989169}
}



@article {NgWillcox2014,
author = {Ng, Leo W. T. and Willcox, Karen E.},
title = {Multifidelity approaches for optimization under uncertainty},
journal = {International Journal for Numerical Methods in Engineering},
volume = {100},
number = {10},
issn = {1097-0207},
url = {http://dx.doi.org/10.1002/nme.4761},
doi = {10.1002/nme.4761},
pages = {746--772},
keywords = {multifidelity, design under uncertainty, model reduction, optimization, probabilistic methods, stochastic problems},
year = {2014},
}



@article{fowlerAgile2001,
  title = {The agile manifesto},
  url = {http://www.pmp-projects.org/Agile-Manifesto.pdf},
  abstract = {In the past 12–18 months, a wide range of publications—Software Development, IEEE Software, Cutter IT Journal, Software Testing and Quality Engineering, and even The Economist—has published articles on what Martin Fowler calls the New Methodology (see ...},
  timestamp = {2014-12-22T00:19:07Z},
  journaltitle = {Software Development},
  journal = {Software Development},
  year = {2001},
  shortjournal = {Softw. Dev.},
  author = {Fowler, M and Highsmith, J},
  date = {2001-01-01},
  file = {2001 Fowler:/Users/ben/Documents/zotero/storage/P7AM7DN2/2001 Fowler.pdf:application/pdf}
}



@article{swiftLive2016,
  title = {Live {{Programming}} in {{Scientific Simulation}}},
  volume = {3},
  timestamp = {2016-02-17T02:30:31Z},
  number = {1},
  year={2016},
  journaltitle = {Journal of Supercomputing Frontiers and Innovations},
  journal = {Journal of Supercomputing Frontiers and Innovations},
  shortjournal = {J. Supercomput. Front. Innov.},
  author = {Swift, Ben and Sorensen, Andrew and Gardner, Henry and Davis, Peter and Decyk, Viktor K.},
  date = {[to appear]}
}

@book{quarteroni2015reduced,
  title={Reduced Basis Methods for Partial Differential Equations: An Introduction},
  author={Quarteroni, A. and Manzoni, A. and Negri, F.},
  isbn={9783319154312},
  lccn={2015930287},
  series={UNITEXT},
  url={https://books.google.com.au/books?id=e6FnCgAAQBAJ},
  year={2015},
  publisher={Springer International Publishing}
}


@incollection{SU2,
	Annote = {doi:10.2514/6.2013-287},
	Author = {Francisco Palacios and Juan Alonso and Karthikeyan Duraisamy and Michael Colonno and Jason Hicken and Aniket Aranake and Alejandro Campos and Sean Copeland and Thomas Economon and Amrita Lonkar and Trent Lukaczyk and Thomas Taylor},
	Booktitle = {51st AIAA Aerospace Sciences Meeting including the New Horizons Forum and Aerospace Exposition},
	Date-Added = {2016-02-18 05:02:51 +0000},
	Date-Modified = {2016-02-18 05:02:51 +0000},
	Doi = {doi:10.2514/6.2013-287},
	M1 = {0},
	M3 = {doi:10.2514/6.2013-287},
	Month = {2016/02/17},
	Publisher = {American Institute of Aeronautics and Astronautics},
	Title = {Stanford University Unstructured (SU$^{2}$): An open-source integrated computational environment for multi-physics simulation and design},
	Title1 = {Aerospace Sciences Meetings},
	Ty = {CHAP},
	Url = {http://dx.doi.org/10.2514/6.2013-287},
	Year = {2013},
	Year1 = {2013/01/05},
	Bdsk-Url-1 = {http://dx.doi.org/10.2514/6.2013-287}
}

@article{Ali11022016,
author = {Ali, Md Mohsin and Strazdins, Peter E and Harding, Brendan and Hegland, Markus}, 
title = {Complex scientific applications made fault-tolerant with the sparse grid combination technique},
year = {2016}, 
doi = {10.1177/1094342015628056}, 
URL = {http://hpc.sagepub.com/content/early/2016/02/10/1094342015628056.abstract}, 
eprint = {http://hpc.sagepub.com/content/early/2016/02/10/1094342015628056.full.pdf+html}, 
journal = {International Journal of High Performance Computing Applications} 
}

@article{GilksEtal1994,
 ISSN = {00390526, 14679884},
 URL = {http://www.jstor.org/stable/2348942},
 abstract = {Markov chain Monte Carlo (MCMC) techniques, such as the Gibbs sampler, are increasingly being used for Bayesian inference. We propose a new MCMC method: adaptive direction sampling (ADS) which, unlike the Gibbs sampler, involves sampling in directions which adapt to the target density. We present non-technically the essence of ADS, but with sufficient detail to allow the practitioner to apply the method. We demonstrate irreducibility of the snooker algorithm, a special case of ADS. We compare the performance of special cases of ADS, including the snooker algorithm and the Gibbs sampler, in a simple test example.},
 author = {W. R. Gilks, G. O. Roberts, E. I. George},
 journal = {Journal of the Royal Statistical Society. Series D (The Statistician)},
 number = {1},
 pages = {179-189},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Adaptive Direction Sampling},
 volume = {43},
 year = {1994}
}


